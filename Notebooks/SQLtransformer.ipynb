{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816bf2a7",
   "metadata": {},
   "source": [
    "# TEXT2SQL with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4acf53ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTroch Version: 1.8.1\n",
      "Transfomers Version: 4.6.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "\n",
    "from typing import Tuple, Dict, List, Union, Any\n",
    "print(f\"PyTroch Version: {torch.__version__}\")\n",
    "print(f\"Transfomers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f54461a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f922ae63",
   "metadata": {},
   "source": [
    "## Data to build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b720bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import records\n",
    "\n",
    "schema_re = re.compile(r'\\((.+)\\)')\n",
    "num_re = re.compile(r'[-+]?\\d*\\.\\d+|\\d+')\n",
    "\n",
    "db_path = Path(\"./private\")\n",
    "db = records.Database(f\"sqlite:///{db_path / 'samsung_new.db'}\")\n",
    "\n",
    "table_id = \"receipts\"\n",
    "table_info = db.query('SELECT sql from sqlite_master WHERE tbl_name = :name', name=table_id).all()[0].sql\n",
    "schema_str = schema_re.findall(table_info.replace(\"\\n\", \"\"))[0]\n",
    "schema = {}\n",
    "for tup in schema_str.split(', '):\n",
    "    c, t = tup.split()\n",
    "    schema[c.strip('\"')] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b15d1272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 'INTEGER',\n",
       " 'rcept_no': 'TEXT',\n",
       " 'reprt_code': 'TEXT',\n",
       " 'bsns_year': 'INTEGER',\n",
       " 'corp_code': 'TEXT',\n",
       " 'stock_code': 'TEXT',\n",
       " 'fs_div': 'TEXT',\n",
       " 'fs_nm': 'TEXT',\n",
       " 'sj_div': 'TEXT',\n",
       " 'sj_nm': 'TEXT',\n",
       " 'account_nm': 'TEXT',\n",
       " 'thstrm_nm': 'TEXT',\n",
       " 'thstrm_dt': 'TEXT',\n",
       " 'thstrm_amount': 'INTEGER',\n",
       " 'frmtrm_nm': 'TEXT',\n",
       " 'frmtrm_dt': 'TEXT',\n",
       " 'frmtrm_amount': 'INTEGER',\n",
       " 'bfefrmtrm_nm': 'TEXT',\n",
       " 'bfefrmtrm_dt': 'TEXT',\n",
       " 'bfefrmtrm_amount': 'INTEGER'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sqlite can have NULL, INTEGER, REAL, TEXT, BLOB data type\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bdf2fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INTEGER', 'TEXT'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(schema.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9a25a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 제 51 기에 삼성전자의 유동자산은 어떻게 돼? [T] receipts [C] index [INTEGER] [C] rcept_no [TEXT] [C] reprt_code [TEXT] [C] bsns_year [INTEGER] [C] corp_code [TEXT] [C] stock_code [TEXT] [C] fs_div [TEXT] [C] fs_nm [TEXT] [C] sj_div [TEXT] [C] sj_nm [TEXT] [C] account_nm [TEXT] [C] thstrm_nm [TEXT] [C] thstrm_dt [TEXT] [C] thstrm_amount [INTEGER] [C] frmtrm_nm [TEXT] [C] frmtrm_dt [TEXT] [C] frmtrm_amount [INTEGER] [C] bfefrmtrm_nm [TEXT] [C] bfefrmtrm_dt [TEXT] [C] bfefrmtrm_amount [INTEGER]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"제 51 기에 삼성전자의 유동자산은 어떻게 돼?\"\n",
    "cls_token = \"[CLS]\"\n",
    "table_token = \"[T]\"\n",
    "column_token = \"[C]\"\n",
    "\n",
    "f\"{cls_token} {question} [T] {table_id} \" + \" \".join([f\"{column_token} {col} [{typ}]\" for col, typ in schema.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1874372a",
   "metadata": {},
   "source": [
    "## Build a cumstom Tokenizer\n",
    "\n",
    "https://huggingface.co/docs/tokenizers/python/latest/pipeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d144a61",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "- `normalizers`는 raw text를 더 깨끗하게 만드는 과정이다.\n",
    "- `NFD` 사용하게 되면 한글은 자음 모음으로 분리된다.\n",
    "    - NFD(Normalization Form Canonical Decomposition) = 조합형\n",
    "    - NFC(Normalizaiton Form Canonical Compostion) = 완성형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8cbfb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제 51 기에 삼성전자의 유동자산은 어떻게 돼?\n",
      "ᄌ/ᅦ/ /5/1/ /ᄀ/ᅵ/ᄋ/ᅦ/ /ᄉ/ᅡ/ᆷ/ᄉ/ᅥ/ᆼ/ᄌ/ᅥ/ᆫ/ᄌ/ᅡ/ᄋ/ᅴ/ /ᄋ/ᅲ/ᄃ/ᅩ/ᆼ/ᄌ/ᅡ/ᄉ/ᅡ/ᆫ/ᄋ/ᅳ/ᆫ/ /ᄋ/ᅥ/ᄄ/ᅥ/ᇂ/ᄀ/ᅦ/ /ᄃ/ᅫ/?\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import NFD, StripAccents\n",
    "\n",
    "normalizer = normalizers.Sequence([NFD(), StripAccents()])\n",
    "# 일반 출력시 합쳐져서 보이지만, for문을 사용하면 분리된다. \n",
    "print(normalizer.normalize_str(question))\n",
    "print(\"/\".join([x for x in normalizer.normalize_str(question)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e3f533",
   "metadata": {},
   "source": [
    "### Pre-Tokenization\n",
    "\n",
    "- `pre_tokenizers`는 텍스트를 더 작은 토큰으로 분리하는 과정이다.\n",
    "- `Whitespace`는 토큰을 공백을 기준으로 나누면 string의 위치를 같이 반환한다. (start + end) - 기준 regex: `\\w+|[^\\w\\s]+`\n",
    "- `Punctuation`은 문장 부호를 각각 분리한다. \n",
    "- `Digits`를 통해 숫자를 각각 분리할지 말지 결정할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "010caa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitespace: \n",
      "[('제', (0, 1)), ('51', (2, 4)), ('기에', (5, 7)), ('삼성전자의', (8, 13)), ('유동자산은', (14, 19)), ('어떻게', (20, 23)), ('돼', (24, 25)), ('?', (25, 26))]\n",
      "Digits individual: False\n",
      "[('제', (0, 1)), ('51', (2, 4)), ('기에', (5, 7)), ('삼성전자의', (8, 13)), ('유동자산은', (14, 19)), ('어떻게', (20, 23)), ('돼', (24, 25)), ('?????', (25, 30))]\n",
      "Punctuation + Individual Digits\n",
      "[('제', (0, 1)), ('5', (2, 3)), ('1', (3, 4)), ('기에', (5, 7)), ('삼성전자의', (8, 13)), ('유동자산은', (14, 19)), ('어떻게', (20, 23)), ('돼', (24, 25)), ('?', (25, 26)), ('?', (26, 27)), ('?', (27, 28)), ('?', (28, 29)), ('?', (29, 30))]\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import pre_tokenizers\n",
    "from tokenizers.pre_tokenizers import Whitespace, Punctuation, Digits\n",
    "\n",
    "print(\"Whitespace: \")\n",
    "print(Whitespace().pre_tokenize_str(question))\n",
    "\n",
    "print(\"Digits individual: False\")\n",
    "pre_tokenizer = pre_tokenizers.Sequence([Whitespace(), Digits(individual_digits=False)])\n",
    "print(pre_tokenizer.pre_tokenize_str(question + \"????\"))\n",
    "\n",
    "print(\"Punctuation + Individual Digits\")\n",
    "pre_tokenizer = pre_tokenizers.Sequence([Whitespace(), Punctuation(), Digits(individual_digits=True)])\n",
    "print(pre_tokenizer.pre_tokenize_str(question + \"????\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e6db3a",
   "metadata": {},
   "source": [
    "### The Model\n",
    "\n",
    "- `BPE`: Byte-Pair Encoding 토큰화, 자주 등장하는 character를 합쳐서 표현하는 알고리즘\n",
    "- `Unigram`: 확률적으로 최적의 subword 토큰을 결정\n",
    "- `WordLevel`: 단어 단위의 토큰화\n",
    "- `WordPiece`: Google WordPiece 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d121f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.models import BPE, Unigram, WordLevel, WordPiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a6d58",
   "metadata": {},
   "source": [
    "### Post-Processing\n",
    "\n",
    "- `processors` 에서 후처리를 할 수 있다.\n",
    "- `TemplateProcessing`을 이용해 원하는 형태로 토큰을 분리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb8c6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.processors import PostProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b53cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "post_processor = TemplateProcessing(\n",
    "    single=\"[CLS] $A [T] $B [C] $B\",\n",
    "    pair=\"[CLS] $A [T] $B:1 [C] $B:1\",\n",
    "    special_tokens=[(\"[CLS]\", 1), (\"[SEP]\", 2)]#, (\"[T]\", 3), (\"[C]\", 4), (\"[INTEGER]\", 5), (\"[REAL]\", 6), (\"[TEXT]\", 7), (\"[BLOB]\", 8)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67240bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a731c83",
   "metadata": {},
   "source": [
    "- https://huggingface.co/docs/tokenizers/python/latest/index.html\n",
    "- https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=pretrainedtokenizer#transformers.PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b4ad754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제 51 기에 삼성전자의 유동자산은 어떻게 돼? [T] receipts [SEP]index[SEP]rcept_no[SEP]reprt_code[SEP]bsns_year[SEP]corp_code[SEP]stock_code[SEP]fs_div[SEP]fs_nm[SEP]sj_div[SEP]sj_nm[SEP]account_nm[SEP]thstrm_nm[SEP]thstrm_dt[SEP]thstrm_amount[SEP]frmtrm_nm[SEP]frmtrm_dt[SEP]frmtrm_amount[SEP]bfefrmtrm_nm[SEP]bfefrmtrm_dt[SEP]bfefrmtrm_amount'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str = f\"{question} [T] {table_id} \" + \"\".join([f\"[SEP]{col}\" for col in schema]) \n",
    "# \" \".join([f\"{column_token} {col} [{typ}]\" for col, typ in schema.items()])\n",
    "input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9516a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_qs = [\"제 51 기에 삼성전자의 유동자산은 어떻게 돼?\", \"2020년도 삼성전자의 유동자산은 얼마?\"]\n",
    "table_str = f\"[T]{table_id}\" + \"\".join([f\"[SEP]{col}\" for col in schema]) \n",
    "batch_ts = [table_str] * len(batch_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dbe3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from KoBertTokenizer import KoBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3b78032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_special_tokens = [\"[T]\", \"[C]\", \"[INTEGER]\", \"[REAL]\", \"[TEXT]\", \"[BLOB]\"]\n",
    "# new_special_tokens = list(map(lambda x: AddedToken(x, single_word=True, normalized=False), new_special_tokens))\n",
    "# tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert', add_special_tokens=True, additional_special_tokens=new_special_tokens)\n",
    "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed778ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokenes2idx = dict(zip(tokenizer.additional_special_tokens, tokenizer.additional_special_tokens_ids))\n",
    "special_tokenes2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b64843e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_input = tokenizer(\n",
    "    batch_qs, batch_ts, \n",
    "    max_length=512, padding=True, truncation=True, return_tensors=\"pt\", \n",
    "    return_attention_mask=True, \n",
    "    return_special_tokens_mask=False, \n",
    ")\n",
    "encode_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ae02cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size, max_length = encode_input[\"input_ids\"].size()\n",
    "question_mask = torch.bitwise_and(encode_input[\"token_type_ids\"] == 0, encode_input[\"attention_mask\"].bool())\n",
    "question_mask[:, 0] = False  # [CLS] mask out\n",
    "question_mask[:, -1] = False  # [SEP] mask out\n",
    "\n",
    "# table_mask = torch.where(\n",
    "#     (encode_input[\"input_ids\"] == 8002), \n",
    "#     torch.ones_like(encode_input[\"input_ids\"], dtype=torch.bool), \n",
    "#     torch.zeros_like(encode_input[\"input_ids\"], dtype=torch.bool)\n",
    "# )\n",
    "# column_mask = torch.where(\n",
    "#     (encode_input[\"input_ids\"] == 8003),\n",
    "#     torch.ones_like(encode_input[\"input_ids\"], dtype=torch.bool), \n",
    "#     torch.zeros_like(encode_input[\"input_ids\"], dtype=torch.bool)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90212370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 제 51 기에 삼성전자의 유동자산은 어떻게 돼?[SEP] [T]receipts[SEP] index[SEP] rcept_no[SEP] reprt_code[SEP] bsns_year[SEP] corp_code[SEP] stock_code[SEP] fs_div[SEP] fs_nm[SEP] sj_div[SEP] sj_nm[SEP] account_nm[SEP] thstrm_nm[SEP] thstrm_dt[SEP] thstrm_amount[SEP] frmtrm_nm[SEP] frmtrm_dt[SEP] frmtrm_amount[SEP] bfefrmtrm_nm[SEP] bfefrmtrm_dt[SEP] bfefrmtrm_amount[SEP]\n",
      "\n",
      "[CLS] 2020년도 삼성전자의 유동자산은 얼마?[SEP] [T]receipts[SEP] index[SEP] rcept_no[SEP] reprt_code[SEP] bsns_year[SEP] corp_code[SEP] stock_code[SEP] fs_div[SEP] fs_nm[SEP] sj_div[SEP] sj_nm[SEP] account_nm[SEP] thstrm_nm[SEP] thstrm_dt[SEP] thstrm_amount[SEP] frmtrm_nm[SEP] frmtrm_dt[SEP] frmtrm_amount[SEP] bfefrmtrm_nm[SEP] bfefrmtrm_dt[SEP] bfefrmtrm_amount[SEP][PAD][PAD]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in encode_input[\"input_ids\"]:\n",
    "    print(tokenizer.decode(x, skip_special_tokens=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d0a753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- type_ids = 0\n",
      "[CLS] 제 51 기에 삼성전자의 유동자산은 어떻게 돼?[SEP]\n",
      "--- type_ids = 1\n",
      "[T]receipts[SEP] index[SEP] rcept_no[SEP] reprt_code[SEP] bsns_year[SEP] corp_code[SEP] stock_code[SEP] fs_div[SEP] fs_nm[SEP] sj_div[SEP] sj_nm[SEP] account_nm[SEP] thstrm_nm[SEP] thstrm_dt[SEP] thstrm_amount[SEP] frmtrm_nm[SEP] frmtrm_dt[SEP] frmtrm_amount[SEP] bfefrmtrm_nm[SEP] bfefrmtrm_dt[SEP] bfefrmtrm_amount[SEP]\n",
      "\n",
      "--- type_ids = 0\n",
      "[CLS] 2020년도 삼성전자의 유동자산은 얼마?[SEP]\n",
      "--- type_ids = 1\n",
      "[T]receipts[SEP] index[SEP] rcept_no[SEP] reprt_code[SEP] bsns_year[SEP] corp_code[SEP] stock_code[SEP] fs_div[SEP] fs_nm[SEP] sj_div[SEP] sj_nm[SEP] account_nm[SEP] thstrm_nm[SEP] thstrm_dt[SEP] thstrm_amount[SEP] frmtrm_nm[SEP] frmtrm_dt[SEP] frmtrm_amount[SEP] bfefrmtrm_nm[SEP] bfefrmtrm_dt[SEP] bfefrmtrm_amount[SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inputs, type_ids in zip(encode_input[\"input_ids\"], encode_input[\"token_type_ids\"]):\n",
    "    print(\"--- type_ids = 0\")\n",
    "    print(tokenizer.decode(inputs[type_ids == 0]).replace(\"[PAD]\", \"\"))\n",
    "    print(\"--- type_ids = 1\")\n",
    "    print(tokenizer.decode(inputs[type_ids == 1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc1f56b",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82b4d6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(8002, 768, padding_idx=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "model = BertModel.from_pretrained(\"monologg/kobert\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e285f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6057dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_output = model(**encode_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "929d43a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encode_output.hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb79a1",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1PW9oAXfW-ZI-jxGn5q9O_gzUIZnNYaet\" alt=\"Sqlova Decoder Architecture \" width=\"100%\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a770de",
   "metadata": {},
   "source": [
    "### Select Column\n",
    "\n",
    "$$\\begin{aligned} \n",
    "s(n\\vert c) &= D_c^T W E_n \\\\\n",
    "p(n\\vert c) &= \\text{softmax}(s(n\\vert c))\\\\\n",
    "C_c &= \\sum_n p(n \\vert c) E_n \\\\\n",
    "s_{sc}(c) &= W  \\tanh ([WD_c; WC_c]) \\\\\n",
    "p_{sc}(c) &= \\text{softmax}(s_{sc}(c))\n",
    "\\end{aligned}$$\n",
    "\n",
    "$E_n$ is LSTM output of $n$-th token of question, $D_c$ is the encoding of header $c$, $C_n$ is context vector of question for given column, $[\\cdot ; \\cdot]$ is concatenation of two vectors, $p_{sc}(c)$ is probability of generating column c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0393e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBEngine:\n",
    "\n",
    "    def __init__(self, fdb):\n",
    "        #fdb = 'data/test.db'\n",
    "        self.db = records.Database('sqlite:///{}'.format(fdb))\n",
    "\n",
    "    def execute_query(self, table_id, query, *args, **kwargs):\n",
    "        return self.execute(table_id, query.sel_index, query.agg_index, query.conditions, *args, **kwargs)\n",
    "\n",
    "    def execute(self, table_id, select_index, aggregation_index, conditions, lower=True):\n",
    "        if not table_id.startswith('table'):\n",
    "            table_id = 'table_{}'.format(table_id.replace('-', '_'))\n",
    "            \n",
    "        table_info = self.db.query('SELECT sql from sqlite_master WHERE tbl_name = :name', name=table_id).all()[0].sql.replace('\\n','')\n",
    "        schema_str = schema_re.findall(table_info)[0]\n",
    "        schema = {}\n",
    "        for tup in schema_str.split(', '):\n",
    "            c, t = tup.split()\n",
    "            schema[c] = t\n",
    "        select = 'col{}'.format(select_index)\n",
    "        agg = agg_ops[aggregation_index]\n",
    "        if agg:\n",
    "            select = '{}({})'.format(agg, select)\n",
    "        where_clause = []\n",
    "        where_map = {}\n",
    "        for col_index, op, val in conditions:\n",
    "            if lower and (isinstance(val, str) or isinstance(val, str)):\n",
    "                val = val.lower()\n",
    "            if schema['col{}'.format(col_index)] == 'real' and not isinstance(val, (int, float)):\n",
    "                try:\n",
    "                    # print('!!!!!!value of val is: ', val, 'type is: ', type(val))\n",
    "                    # val = float(parse_decimal(val)) # somehow it generates error.\n",
    "                    val = float(parse_decimal(val, locale='en_US'))\n",
    "                    # print('!!!!!!After: val', val)\n",
    "\n",
    "                except NumberFormatError as e:\n",
    "                    try:\n",
    "                        val = float(num_re.findall(val)[0]) # need to understand and debug this part.\n",
    "                    except:\n",
    "                        # Although column is of number, selected one is not number. Do nothing in this case.\n",
    "                        pass\n",
    "            where_clause.append('col{} {} :col{}'.format(col_index, cond_ops[op], col_index))\n",
    "            where_map['col{}'.format(col_index)] = val\n",
    "        where_str = ''\n",
    "        if where_clause:\n",
    "            where_str = 'WHERE ' + ' AND '.join(where_clause)\n",
    "        query = 'SELECT {} AS result FROM {} {}'.format(select, table_id, where_str)\n",
    "\n",
    "        #print query\n",
    "        out = self.db.query(query, **where_map)\n",
    "\n",
    "        return [o.result for o in out]\n",
    "\n",
    "    def execute_return_query(self, table_id, select_index, aggregation_index, conditions, lower=True):\n",
    "        if not table_id.startswith('table'):\n",
    "            table_id = 'table_{}'.format(table_id.replace('-', '_'))\n",
    "        table_info = self.db.query('SELECT sql from sqlite_master WHERE tbl_name = :name', name=table_id).all()[0].sql.replace('\\n','')\n",
    "        schema_str = schema_re.findall(table_info)[0]\n",
    "        schema = {}\n",
    "        for tup in schema_str.split(', '):\n",
    "            c, t = tup.split()\n",
    "            schema[c] = t\n",
    "        select = 'col{}'.format(select_index)\n",
    "        agg = agg_ops[aggregation_index]\n",
    "        if agg:\n",
    "            select = '{}({})'.format(agg, select)\n",
    "        where_clause = []\n",
    "        where_map = {}\n",
    "        for col_index, op, val in conditions:\n",
    "            if lower and (isinstance(val, str) or isinstance(val, str)):\n",
    "                val = val.lower()\n",
    "            if schema['col{}'.format(col_index)] == 'real' and not isinstance(val, (int, float)):\n",
    "                try:\n",
    "                    # print('!!!!!!value of val is: ', val, 'type is: ', type(val))\n",
    "                    # val = float(parse_decimal(val)) # somehow it generates error.\n",
    "                    val = float(parse_decimal(val, locale='en_US'))\n",
    "                    # print('!!!!!!After: val', val)\n",
    "\n",
    "                except NumberFormatError as e:\n",
    "                    val = float(num_re.findall(val)[0])\n",
    "            where_clause.append('col{} {} :col{}'.format(col_index, cond_ops[op], col_index))\n",
    "            where_map['col{}'.format(col_index)] = val\n",
    "        where_str = ''\n",
    "        if where_clause:\n",
    "            where_str = 'WHERE ' + ' AND '.join(where_clause)\n",
    "        query = 'SELECT {} AS result FROM {} {}'.format(select, table_id, where_str)\n",
    "\n",
    "        #print query\n",
    "        out = self.db.query(query, **where_map)\n",
    "\n",
    "\n",
    "        return [o.result for o in out], query\n",
    "    def show_table(self, table_id):\n",
    "        if not table_id.startswith('table'):\n",
    "            table_id = 'table_{}'.format(table_id.replace('-', '_'))\n",
    "        rows = self.db.query('select * from ' +table_id)\n",
    "        print(rows.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f236ef46",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a7f80",
   "metadata": {},
   "source": [
    "# SQLova Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36331310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlova.model.nl2sql.wikisql_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba49d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTroch Version: 1.8.1\n",
      "Transfomers Version: 4.6.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "\n",
    "from typing import Tuple, Dict, List, Union, Any\n",
    "print(f\"PyTroch Version: {torch.__version__}\")\n",
    "print(f\"Transfomers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34066108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    path_sql = Path(\"NLSQL.jsonl\")\n",
    "    path_table = Path(\"table.jsonl\")\n",
    "\n",
    "    data = []\n",
    "    table = {}\n",
    "    with path_sql.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            t1 = json.loads(line.strip())\n",
    "            data.append(t1)\n",
    "\n",
    "    with path_table.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            t1 = json.loads(line.strip())\n",
    "            table[t1['id']] = t1\n",
    "            \n",
    "    return data, table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a708bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, table = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547d9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# multiprocessing lib doesn’t have it implemented on Windows\n",
    "# https://discuss.pytorch.org/t/cant-pickle-local-object-dataloader-init-locals-lambda/31857/14\n",
    "num_workers = 0 if os.name == \"nt\" else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb24238",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    batch_size=2,\n",
    "    dataset=data,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=lambda x: x # now dictionary values are not merged!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005fdc5",
   "metadata": {},
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae7db5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsv2jsonl import DBEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1521e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = Path(\"./private\")\n",
    "dbengine = DBEngine(db_path / \"samsung_new.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af90b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_schema_lengths = []\n",
    "for t in dbengine.db.get_table_names():\n",
    "    dbengine.get_schema_info(t)\n",
    "    table_schema_lengths.append(len(dbengine.schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b77d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = DBEngine(db_path / \"samsung_new.db\")\n",
    "# engine.execute(table_id=\"receipts\", query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b126334",
   "metadata": {},
   "source": [
    "get models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2cbc25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from KoBertTokenizer import KoBertTokenizer\n",
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "def get_bert(model_path: str, device: str, max_col_length: int, output_hidden_states: bool=False):\n",
    "    \n",
    "    special_tokens = [\"[S]\", \"[E]\", \"[COL]\"] # sequence start, sequence end, column tokens\n",
    "    tokenizer = KoBertTokenizer.from_pretrained(model_path, add_special_tokens=True, additional_special_tokens=special_tokens)\n",
    "    config = BertConfig.from_pretrained(model_path)\n",
    "    config.output_hidden_states = output_hidden_states\n",
    "    \n",
    "    model = BertModel.from_pretrained(model_path)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.config.output_hidden_states = output_hidden_states\n",
    "    model.to(device)\n",
    "    \n",
    "    return model, tokenizer, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d38dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"monologg/kobert\"\n",
    "device = \"cpu\" # \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "\n",
    "agg_ops = ['', 'MAX', 'MIN', 'COUNT', 'SUM', 'AVG']\n",
    "cond_ops = ['=', '>', '<', 'OP']\n",
    "\n",
    "num_target_layers = 1  # \"The Number of final layers of BERT to be used in downstream task.\"\n",
    "# Get BERT\n",
    "model_bert, tokenizer_bert, config_bert = get_bert(model_path=model_path, device=device, max_col_length=max(table_schema_lengths))\n",
    "\n",
    "# Get Seq-to-SQL\n",
    "iS = config_bert.hidden_size * num_target_layers  # Seq-to-SQL input vector dimenstion\n",
    "hS = 100\n",
    "lS = 2\n",
    "dr = 0.3\n",
    "\n",
    "n_cond_ops = len(cond_ops)\n",
    "n_agg_ops = len(agg_ops)\n",
    "model = Seq2SQL_v1(iS, hS, lS, dr, n_cond_ops, n_agg_ops)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d5b3d",
   "metadata": {},
   "source": [
    "get parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eb9ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr_bert = 1e-5\n",
    "\n",
    "opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                               lr=lr, weight_decay=0)\n",
    "opt_bert = torch.optim.AdamW(filter(lambda p: p.requires_grad, model_bert.parameters()),\n",
    "                            lr=lr_bert, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20b0d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model_bert.train()\n",
    "\n",
    "ave_loss = 0\n",
    "cnt = 0  # count the # of examples\n",
    "cnt_sc = 0  # count the # of correct predictions of select column\n",
    "cnt_sa = 0  # of selectd aggregation\n",
    "cnt_wn = 0  # of where number\n",
    "cnt_wc = 0  # of where column\n",
    "cnt_wo = 0  # of where operator\n",
    "cnt_wv = 0  # of where-value\n",
    "cnt_wvi = 0  # of where-value index (on question tokens)\n",
    "cnt_lx = 0  # of logical form acc\n",
    "cnt_x = 0  # of execution acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0875f63b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9298a6ab9ef2498db9e73cb6bad8c174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TRAIN:   0%|          | 0/21120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "st_pos = 0\n",
    "\n",
    "for iB, data in enumerate(tqdm(data_loader, desc='TRAIN')):\n",
    "    cnt += len(data)\n",
    "    \n",
    "    if cnt < st_pos:\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25590739",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tkn = tokenizer_bert.additional_special_tokens[0]\n",
    "start_tkn_id = tokenizer_bert.additional_special_tokens_ids[0]\n",
    "end_tkn = tokenizer_bert.additional_special_tokens[1]\n",
    "end_tkn_id = tokenizer_bert.additional_special_tokens_ids[1]\n",
    "\n",
    "batch_qs = [jsonl[\"question\"] for jsonl in data]\n",
    "tid = [jsonl[\"table_id\"] for jsonl in data]\n",
    "batch_sqls = [jsonl[\"sql\"] for jsonl in data]\n",
    "batch_ts = []\n",
    "for table_id in tid:\n",
    "    dbengine.get_schema_info(table_id)\n",
    "    table_str = f\"{start_tkn}{table_id}{end_tkn}\" + \"\".join([\n",
    "        f\"[COL]{start_tkn}{col}{end_tkn}\" for col in dbengine.schema\n",
    "    ]) \n",
    "    batch_ts.append(table_str)\n",
    "    \n",
    "encode_input = tokenizer_bert(\n",
    "    batch_qs, batch_ts, \n",
    "    max_length=512, padding=True, truncation=True, return_tensors=\"pt\", \n",
    "    return_attention_mask=True, \n",
    "    return_special_tokens_mask=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6a9e774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 삼성전자의 2017년 법인세차감전 순이익은 얼마야?[SEP] [S] receipts [E] [COL] [S] index [E] [COL] [S] rcept_no [E] [COL] [S] reprt_code [E] [COL] [S] bsns_year [E] [COL] [S] corp_code [E] [COL] [S] stock_code [E] [COL] [S] fs_div [E] [COL] [S] fs_nm [E] [COL] [S] sj_div [E] [COL] [S] sj_nm [E] [COL] [S] account_nm [E] [COL] [S] thstrm_nm [E] [COL] [S] thstrm_dt [E] [COL] [S] thstrm_amount [E] [COL] [S] frmtrm_nm [E] [COL] [S] frmtrm_dt [E] [COL] [S] frmtrm_amount [E] [COL] [S] bfefrmtrm_nm [E] [COL] [S] bfefrmtrm_dt [E] [COL] [S] bfefrmtrm_amount [E] [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_bert.decode(encode_input[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73371609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(input_ids, mask, batch_size, start_tkn_id, end_tkn_id):\n",
    "    r\"\"\"\n",
    "    answer should include end token: [E]\n",
    "    \"\"\"\n",
    "    masked_input_ids = input_ids[mask]\n",
    "    start_tkn_mask = masked_input_ids == start_tkn_id\n",
    "    end_tkn_mask = masked_input_ids == end_tkn_id\n",
    "    table_col_length = masked_input_ids.view(batch_size, -1).size(1)\n",
    "    start_end_mask = torch.bitwise_or(start_tkn_mask, end_tkn_mask)\n",
    "    index = torch.arange(table_col_length).repeat(batch_size)[start_end_mask].view(batch_size, -1, 2)\n",
    "    tkn_lengths = index[:, :, 1] - index[:, :, 0]\n",
    "    answer_col_tkns = [x.split(tkn_length.tolist()) for x, tkn_length in zip(\n",
    "        masked_input_ids[~start_tkn_mask].view(batch_size, -1), tkn_lengths)]\n",
    "    return answer_col_tkns\n",
    "\n",
    "# def get_decoder_input_mask(input_ids, mask, batch_size, end_tkn_id):\n",
    "#     r\"\"\"\n",
    "#     input should only include end token: [S]\n",
    "#     \"\"\"\n",
    "#     end_tkn_mask = input_ids == end_tkn_id\n",
    "#     end_index = torch.arange(input_ids.size(1)).repeat(batch_size)[end_tkn_mask.view(-1)].view(batch_size, -1)\n",
    "#     return mask.scatter(1, end_index, False)\n",
    "\n",
    "def get_decoder_input_mask(input_ids, mask, batch_size, end_tkn_id):\n",
    "    r\"\"\"\n",
    "    input should only contains word tokens:\n",
    "    \"\"\"\n",
    "    start_tkn_mask = input_ids == start_tkn_id\n",
    "    end_tkn_mask = input_ids == end_tkn_id\n",
    "    start_end_mask = torch.bitwise_or(start_tkn_mask, end_tkn_mask)\n",
    "    index = torch.arange(input_ids.size(1)).repeat(batch_size)[start_end_mask.view(-1)].view(batch_size, -1)\n",
    "    return mask.scatter(1, index, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "808a00d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_mask_and_answer(encode_input, tokenizer):\n",
    "    r\"\"\"\n",
    "    table -> database table name(id)\n",
    "    header -> database header\n",
    "    \n",
    "    returns:\n",
    "        input_question_mask, input_table_mask, input_header_mask, answer_table_tkns, answer_header_tkns\n",
    "    \"\"\"\n",
    "    batch_size, max_length = encode_input[\"input_ids\"].size()\n",
    "    sep_tkn_mask = encode_input[\"input_ids\"] == tokenizer.sep_token_id\n",
    "    start_tkn_id, end_tkn_id, col_tkn_id = tokenizer.additional_special_tokens_ids\n",
    "    \n",
    "    input_question_mask = torch.bitwise_and(encode_input[\"token_type_ids\"] == 0, encode_input[\"attention_mask\"].bool())\n",
    "    input_question_mask = torch.bitwise_and(input_question_mask, ~sep_tkn_mask) # [SEP] mask out\n",
    "    input_question_mask[:, 0] = False  # [CLS] mask out\n",
    "\n",
    "    db_mask = torch.bitwise_and(encode_input[\"token_type_ids\"] == 1, encode_input[\"attention_mask\"].bool())\n",
    "    db_mask = torch.bitwise_xor(db_mask, sep_tkn_mask)\n",
    "    col_tkn_mask = encode_input[\"input_ids\"] == col_tkn_id\n",
    "    db_mask = torch.bitwise_and(db_mask, ~col_tkn_mask)\n",
    "    # split table_mask and header_mask\n",
    "    input_idx = torch.arange(max_length).repeat(batch_size, 1)\n",
    "    db_idx = input_idx[db_mask]\n",
    "    table_header_tkn_idx = db_idx[db_idx > 0]\n",
    "    table_start_idx = table_header_tkn_idx.view(batch_size, -1)[:, 0] + 1\n",
    "    start_tkn_idx = table_header_tkn_idx[1:][table_header_tkn_idx.diff() == 2].view(batch_size, -1)\n",
    "    table_end_sep_idx = start_tkn_idx[:, 0] - 1\n",
    "    split_size = torch.stack([\n",
    "        table_end_sep_idx-table_start_idx+1, table_header_tkn_idx.view(batch_size, -1).size(1)-(table_end_sep_idx-table_start_idx+1)\n",
    "    ]).transpose(0, 1)\n",
    "\n",
    "    # Token idx\n",
    "    table_tkn_idx, header_tkn_idx = map(\n",
    "        lambda x: torch.stack(x), \n",
    "        zip(*[torch.split(x, size.tolist()) for x, size in zip(table_header_tkn_idx.view(batch_size, -1), split_size)])\n",
    "    )\n",
    "\n",
    "    table_tkn_idx = table_tkn_idx[:, 1:]\n",
    "    # Mask include [S] & [E] tokens\n",
    "    table_tkn_mask = torch.zeros_like(encode_input[\"input_ids\"], dtype=torch.bool).scatter(1, table_tkn_idx, True)\n",
    "    header_tkn_mask = torch.zeros_like(encode_input[\"input_ids\"], dtype=torch.bool).scatter(1, header_tkn_idx, True)\n",
    "\n",
    "    # For Decoder Input, Maskout [S], [E] for table & header  \n",
    "    input_table_mask = get_decoder_input_mask(\n",
    "        encode_input[\"input_ids\"], table_tkn_mask, batch_size, end_tkn_id\n",
    "    )\n",
    "    input_header_mask = get_decoder_input_mask(\n",
    "        encode_input[\"input_ids\"], header_tkn_mask, batch_size, end_tkn_id\n",
    "    )\n",
    "    # [COL] token mask: this is for attention\n",
    "    col_tkn_idx = input_idx[col_tkn_mask].view(batch_size, -1)\n",
    "    input_col_mask = torch.zeros_like(encode_input[\"input_ids\"], dtype=torch.bool).scatter(1, col_tkn_idx, True)\n",
    "        \n",
    "    # For Answer, Maskout [S] for table & header \n",
    "    answer_table_tkns = get_answer(\n",
    "        encode_input[\"input_ids\"], table_tkn_mask, batch_size, start_tkn_id, end_tkn_id\n",
    "    )\n",
    "    answer_header_tkns = get_answer(\n",
    "        encode_input[\"input_ids\"], header_tkn_mask, batch_size, start_tkn_id, end_tkn_id\n",
    "    )\n",
    "    \n",
    "    return input_question_mask, input_table_mask, input_header_mask, input_col_mask, answer_table_tkns, answer_header_tkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a25c2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_question_mask, input_table_mask, input_header_mask, input_col_mask, answer_table_tkns, answer_header_tkns \\\n",
    "    = get_input_mask_and_answer(encode_input, tokenizer_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5412574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자의 2017년 법인세차감전 순이익은 얼마야? 삼성전자 50기 유동자산이 어때?\n",
      "receipts receipts\n",
      "index rcept_no reprt_code bsns_year corp_code stock_code fs_div fs_nm sj_div sj_nm account_nm thstrm_nm thstrm_dt thstrm_amount frmtrm_nm frmtrm_dt frmtrm_amount bfefrmtrm_nm bfefrmtrm_dt bfefrmtrm_amount index rcept_no reprt_code bsns_year corp_code stock_code fs_div fs_nm sj_div sj_nm account_nm thstrm_nm thstrm_dt thstrm_amount frmtrm_nm frmtrm_dt frmtrm_amount bfefrmtrm_nm bfefrmtrm_dt bfefrmtrm_amount\n",
      "[COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL] [COL]\n",
      "---answer table tokens---\n",
      "[(tensor([ 517,  437,  382,  389,  405,  432,  442,  440, 8003]),), (tensor([ 517,  437,  382,  389,  405,  432,  442,  440, 8003]),)]\n",
      "---answer column tokens---\n",
      "--- batch ---\n",
      "tensor([ 517,  409,  388,  389,  457, 8003])\n",
      "tensor([ 517,  435,  382,  389,  432,  442,  365,  425,  427, 8003])\n",
      "tensor([ 517,  437,  432,  435,  442,  365,  385,  388,  389, 8003])\n",
      "tensor([ 517,  380,  440,  425,  440,  365,  458,  389,  375, 8003])\n",
      "tensor([ 705,  430,  432,  365,  385,  388,  389, 8003])\n",
      "tensor([ 517,  441,  427,  382,  415,  365,  385,  388,  389, 8003])\n",
      "tensor([ 517,  398,  440,  365,  388,  405,  453, 8003])\n",
      "tensor([ 517,  398,  440,  365,  425,  423, 8003])\n",
      "tensor([ 517,  440,  414,  365,  388,  405,  453, 8003])\n",
      "tensor([ 517,  440,  414,  365,  425,  423, 8003])\n",
      "tensor([ 517,  369,  385,  449,  442,  365,  425,  423, 8003])\n",
      "tensor([ 517,  444,  441,  435,  423,  365,  425,  423, 8003])\n",
      "tensor([ 517,  444,  441,  435,  423,  365,  388,  442, 8003])\n",
      "tensor([ 517,  444,  441,  435,  423,  365,  373,  427,  449,  442, 8003])\n",
      "tensor([ 517,  398,  435,  423,  442,  435,  423,  365,  425,  423, 8003])\n",
      "tensor([ 517,  398,  435,  423,  442,  435,  423,  365,  388,  442, 8003])\n",
      "tensor([ 517,  398,  435,  423,  442,  435,  423,  365,  373,  427,  449,  442,\n",
      "        8003])\n",
      "tensor([ 517,  380,  398,  389,  398,  435,  423,  442,  435,  423,  365,  425,\n",
      "         423, 8003])\n",
      "tensor([ 517,  380,  398,  389,  398,  435,  423,  442,  435,  423,  365,  388,\n",
      "         442, 8003])\n",
      "tensor([ 517,  380,  398,  389,  398,  435,  423,  442,  435,  423,  365,  373,\n",
      "         427,  449,  442, 8003])\n",
      "--- batch ---\n",
      "tensor([ 517,  409,  388,  389,  457, 8003])\n",
      "tensor([ 517,  435,  382,  389,  432,  442,  365,  425,  427, 8003])\n",
      "tensor([ 517,  437,  432,  435,  442,  365,  385,  388,  389, 8003])\n",
      "tensor([ 517,  380,  440,  425,  440,  365,  458,  389,  375, 8003])\n",
      "tensor([ 705,  430,  432,  365,  385,  388,  389, 8003])\n",
      "tensor([ 517,  441,  427,  382,  415,  365,  385,  388,  389, 8003])\n",
      "tensor([ 517,  398,  440,  365,  388,  405,  453, 8003])\n",
      "tensor([ 517,  398,  440,  365,  425,  423, 8003])\n",
      "tensor([ 517,  440,  414,  365,  388,  405,  453, 8003])\n",
      "tensor([ 517,  440,  414,  365,  425,  423, 8003])\n",
      "tensor([ 517,  369,  385,  449,  442,  365,  425,  423, 8003])\n",
      "tensor([ 517,  444,  441,  435,  423,  365,  425,  423, 8003])\n",
      "tensor([ 517,  444,  441,  435,  423,  365,  388,  442, 8003])\n",
      "tensor([ 517,  444,  441,  435,  423,  365,  373,  427,  449,  442, 8003])\n",
      "tensor([ 517,  398,  435,  423,  442,  435,  423,  365,  425,  423, 8003])\n",
      "tensor([ 517,  398,  435,  423,  442,  435,  423,  365,  388,  442, 8003])\n",
      "tensor([ 517,  398,  435,  423,  442,  435,  423,  365,  373,  427,  449,  442,\n",
      "        8003])\n",
      "tensor([ 517,  380,  398,  389,  398,  435,  423,  442,  435,  423,  365,  425,\n",
      "         423, 8003])\n",
      "tensor([ 517,  380,  398,  389,  398,  435,  423,  442,  435,  423,  365,  388,\n",
      "         442, 8003])\n",
      "tensor([ 517,  380,  398,  389,  398,  435,  423,  442,  435,  423,  365,  373,\n",
      "         427,  449,  442, 8003])\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_bert.decode(encode_input[\"input_ids\"][input_question_mask]))\n",
    "print(tokenizer_bert.decode(encode_input[\"input_ids\"][input_table_mask]))\n",
    "print(tokenizer_bert.decode(encode_input[\"input_ids\"][input_header_mask]))\n",
    "print(tokenizer_bert.decode(encode_input[\"input_ids\"][input_col_mask]))\n",
    "print(\"---answer table tokens---\")\n",
    "print(answer_table_tkns)\n",
    "print(\"---answer column tokens---\")\n",
    "for b in answer_header_tkns:\n",
    "    print(\"--- batch ---\")\n",
    "    for x in b:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec38c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_outputs = model_bert(**encode_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fed6ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f27e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(batches: Tuple[torch.Tensor], lengths: List[int], model: BertModel, pad_idx: int=1) -> torch.Tensor:\n",
    "    padded = []\n",
    "    max_length = max(lengths)\n",
    "    for x in batches:\n",
    "        if len(x) < max_length:\n",
    "            pad_tensor = model.embeddings.word_embeddings(torch.LongTensor([pad_idx]*(max_length - len(x))))\n",
    "            padded.append(torch.cat([x, pad_tensor]))\n",
    "        else:\n",
    "            padded.append(x)\n",
    "    return torch.stack(padded)\n",
    "\n",
    "def get_decoder_batches(encode_output, mask, model, pad_idx):\n",
    "    lengths = mask.sum(1)\n",
    "    tensors = encode_output.last_hidden_state[mask, :]\n",
    "    batches = torch.split(tensors, lengths.tolist())\n",
    "    if lengths.ne(lengths.max()).sum().item() != 0:\n",
    "        # pad not same length tokens\n",
    "        tensors_padded = pad(batches, lengths.tolist(), model, pad_idx=pad_idx)\n",
    "    else:\n",
    "        # just stack the splitted tensors\n",
    "        tensors_padded = torch.stack(batches)\n",
    "    return tensors_padded, lengths.tolist()\n",
    "\n",
    "def get_pad_mask(lengths):\n",
    "    batch_size = len(lengths)\n",
    "    max_len = max(lengths)\n",
    "    mask = torch.ones(batch_size, max_len)\n",
    "    for i, l in enumerate(lengths):\n",
    "        mask[i, :l] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca850272",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_padded, question_lengths = get_decoder_batches(encode_outputs, input_question_mask, model_bert, pad_idx=tokenizer_bert.pad_token_id)\n",
    "table_padded, table_lengths = get_decoder_batches(encode_outputs, input_table_mask, model_bert, pad_idx=tokenizer_bert.pad_token_id)\n",
    "header_padded, header_lengths = get_decoder_batches(encode_outputs, input_header_mask, model_bert, pad_idx=tokenizer_bert.pad_token_id)\n",
    "col_padded, col_lengths = get_decoder_batches(encode_outputs, input_col_mask, model_bert, pad_idx=tokenizer_bert.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c6c2467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 14, 768]),\n",
       " torch.Size([2, 8, 768]),\n",
       " torch.Size([2, 181, 768]),\n",
       " torch.Size([2, 20, 768]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_padded.size(), table_padded.size(), header_padded.size(), col_padded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f2c9a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 10]\n",
      "[8, 8]\n",
      "[181, 181]\n",
      "[20, 20]\n"
     ]
    }
   ],
   "source": [
    "print(question_lengths)\n",
    "print(table_lengths)\n",
    "print(header_lengths)\n",
    "print(col_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8611c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_g(batch_sqls):\n",
    "    \"\"\"\n",
    "    for backward compatibility, separated with get_g\n",
    "    \n",
    "    sc: select column\n",
    "    sa: select agg\n",
    "    wn: where number\n",
    "    wc: where column\n",
    "    wo: where operator\n",
    "    wv: where value\n",
    "    \"\"\"\n",
    "    get_ith_element = lambda li, i: [x[i] for x in li]\n",
    "    g_sc = []\n",
    "    g_sa = []\n",
    "    g_wn = []\n",
    "    g_wc = []\n",
    "    g_wo = []\n",
    "    g_wv = []\n",
    "    for b, sql_dict in enumerate(batch_sqls):\n",
    "        g_sc.append( sql_dict[\"sel\"] )\n",
    "        g_sa.append( sql_dict[\"agg\"])\n",
    "\n",
    "        conds = sql_dict[\"conds\"]\n",
    "        if not sql_dict[\"agg\"] < 0:\n",
    "            g_wn.append( len(conds) )\n",
    "            g_wc.append( get_ith_element(conds, 0) )\n",
    "            g_wo.append( get_ith_element(conds, 1) )\n",
    "            g_wv.append( get_ith_element(conds, 2) )\n",
    "        else:\n",
    "            raise EnvironmentError\n",
    "    return g_sc, g_sa, g_wn, g_wc, g_wo, g_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0352ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sc, g_sa, g_wn, g_wc, g_wo, g_wv = get_g(batch_sqls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "842efd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([16, 16],\n",
       " [0, 0],\n",
       " [2, 2],\n",
       " [[10, 3], [10, 3]],\n",
       " [[0, 0], [0, 0]],\n",
       " [['법인세차감전 순이익', 2018], ['유동자산', 2019]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_sc, g_sa, g_wn, g_wc, g_wo, g_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72f3ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def wipe_out_pad_tkn_score(self, score, lengths, dim=2):\n",
    "        max_len = max(lengths)\n",
    "        for batch_idx, length in enumerate(lengths):\n",
    "            if length < max_len:\n",
    "                if dim == 2:\n",
    "                    score[batch_idx, :, length:] = -10000000\n",
    "                elif dim == 1:\n",
    "                    score[batch_idx, length:, :] = 0.0\n",
    "                else:\n",
    "                    raise ValueError(f\"`dim` in wipe_out_pad_tkn_score should be 1 or 2\")\n",
    "        return score \n",
    "\n",
    "\n",
    "class C2QAttention(AttentionBase):\n",
    "    r\"\"\"Decoder Column to Question Attention Module\"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, o_c, o_q, q_lengths, c_lengths=None, rt_attn=False):\n",
    "        r\"\"\"\n",
    "        Calculate for each column tokens, How much related to question tokens?\n",
    "        \n",
    "        o_c: LSTM output of column\n",
    "        o_q: LSTM output of question \n",
    "        \n",
    "        c_lengths: wipe out row length\n",
    "        return context atttended to question tokens\n",
    "        \"\"\"\n",
    "        sqrt_H = torch.sqrt(torch.FloatTensor([o_c.size(-1)], device=o_c.device))  # Apply Attention is All you Need Technique\n",
    "        o_q_transform = self.linear(o_q)  # (B, T_q, H)\n",
    "        score_c2q = torch.bmm(o_c, o_q_transform.transpose(1, 2)) / sqrt_H  # (B, T_c, H) x (B, H, T_q) = (B, T_c, T_q)\n",
    "        score_c2q = self.wipe_out_pad_tkn_score(score_c2q, q_lengths, dim=2)\n",
    "        \n",
    "        prob_c2q = self.softmax(score_c2q)\n",
    "        if c_lengths is not None:\n",
    "            prob_c2q = self.wipe_out_pad_tkn_score(prob_c2q, c_lengths, dim=1)\n",
    "        # prob_c2q: (B, T_c, T_q) -> (B, T_c, T_q, 1)\n",
    "        # o_q: (B, 1, T_q, H)\n",
    "        # p_col2question \\odot o_q = (B, T_c, T_q, 1) \\odot (B, 1, T_q, H) = (B, T_c, T_q, H)\n",
    "        # -> reduce sum to T_q to get context for each column (B, T_c, H)\n",
    "        context = torch.mul(prob_c2q.unsqueeze(3), o_q.unsqueeze(1)).sum(dim=2)\n",
    "        if rt_attn:\n",
    "            attn = prob_c2q\n",
    "        else:\n",
    "            attn = None\n",
    "        return context, attn\n",
    "\n",
    "class SelfAttention(AttentionBase):\n",
    "    r\"\"\"Decoder Self Attention Module\"\"\"\n",
    "    def __init__(self, in_features, out_features=1):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, o, lengths, rt_attn=False):\n",
    "        r\"\"\"\n",
    "        Calculate for each o tokens, How much related to o tokens?\n",
    "        \n",
    "        return attended summary of o\n",
    "        \"\"\"\n",
    "        o_transform = self.linear(o)  # (B, T_o, H) -> (B, T_o, 1)\n",
    "        o_transform = self.wipe_out_pad_tkn_score(o_transform, lengths) \n",
    "        o_prob = self.softmax(o_transform)  # (B, T_o, 1)\n",
    "        \n",
    "        o_summary = torch.mul(o, o_prob).sum(1)  # (B, T_o, H) \\odot (B, T_o, 1) -> (B, H)\n",
    "\n",
    "        if rt_attn:\n",
    "            attn = o_prob\n",
    "        else:\n",
    "            attn = None\n",
    "        return o_summary, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d44e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectDecoder(nn.Module):\n",
    "    r\"\"\"SELECT Decoder\"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, num_layers: int=2, dropout_ratio:float=0.3) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        \n",
    "        self.lstm_q = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        self.lstm_h = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.col_context_linear = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.col2question_attn = C2QAttention(hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(2*hidden_size, 2*hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2*hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, question_padded, header_padded, col_padded, question_lengths: List[int], col_lengths: List[int], rt_attn=False):\n",
    "        r\"\"\"\n",
    "        predict column index\n",
    "        \"\"\"\n",
    "        batch_size, n_col, _ = col_padded.size()\n",
    "        o_q, (h_q, c_q) = self.lstm_q(question_padded)  # o_q: (B, T_q, H)\n",
    "        o_c, (h_c, c_c) = self.lstm_h(col_padded)  # o_c: (B, T_c, H)\n",
    "        o_h, (h_h, c_h) = self.lstm_h(header_padded)  # h_h: (n_direc*num_layers, B, H/2)\n",
    "        \n",
    "        header_summary = torch.cat([h for h in h_h[-2:]], dim=1).unsqueeze(1).repeat(1, n_col, 1)  # (B, T_c, H)\n",
    "        col_context = torch.cat([o_c, header_summary], dim=2)  # (B, T_c, 2H)\n",
    "        col_context = self.col_context_linear(col_context)  # (B, T_c, H)\n",
    "        col_q_context, attn = self.col2question_attn(col_context, o_q, question_lengths, col_lengths, rt_attn)  # (B, T_c, H), (B, T_c, T_q)\n",
    "        \n",
    "        vec = torch.cat([col_q_context, col_context], dim=2)  # (B, T_c, 2H)\n",
    "        output = self.output_layer(vec)\n",
    "        # TODO: add penalty for padded header(column) information\n",
    "        \n",
    "        return output.squeeze(-1), attn\n",
    "    \n",
    "\n",
    "class AggDecoder(nn.Module):\n",
    "    r\"\"\"AGG Decoder\"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, num_layers: int=2, dropout_ratio:float=0.3) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        \n",
    "        self.lstm_q = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        self.lstm_h = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.col_context_linear = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.col2question_attn = C2QAttention(hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "                \n",
    "    def forward(self, question_padded, col_padded, question_lengths: List[int], col_lengths: List[int], select_idxes: List[int], rt_attn=False):\n",
    "        r\"\"\"\n",
    "        predict agg index\n",
    "        select_prob: selected argmax indices of select_output score\n",
    "        \"\"\"\n",
    "        batch_size, n_col, _ = col_padded.size()\n",
    "        o_q, (h_q, c_q) = self.lstm_q(question_padded)  # o_q: (B, T_q, H)\n",
    "        o_c, (h_c, c_c) = self.lstm_h(col_padded)  # o_c: (B, T_c, H)\n",
    "        o_h, (h_h, c_h) = self.lstm_h(header_padded)  # h_h: (n_direc*num_layers, B, H/2)\n",
    "        \n",
    "        header_summary = torch.cat([h for h in h_h[-2:]], dim=1).unsqueeze(1).repeat(1, n_col, 1)  # (B, T_c, H)\n",
    "        col_context = torch.cat([o_c, header_summary], dim=2)  # (B, T_c, 2H)\n",
    "        col_context = self.col_context_linear(col_context)  # (B, T_c, H)\n",
    "        \n",
    "        col_selected = col_context[list(range(batch_size)), select_idxes].unsqueeze(1)  # col_selected: (B, 1, H)\n",
    "        \n",
    "        col_q_context, attn = self.col2question_attn(col_selected, o_q, question_lengths, col_lengths, rt_attn)  # (B, 1, H), (B, 1, T_q)\n",
    "        output = self.output_layer(col_q_context.squeeze(1))\n",
    "        \n",
    "        return output, attn\n",
    "    \n",
    "    \n",
    "class WhereNumDecoder(nn.Module):\n",
    "    r\"\"\"WHERE number Decoder\"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, num_layers: int=2, dropout_ratio:float=0.3, max_where_conds=4) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.max_where_conds = max_where_conds\n",
    "        if self.output_size > self.max_where_conds+1:\n",
    "            # HERE output will be dilivered to cross-entropy loss, not guessing the real number of where clause\n",
    "            raise ValueError(f\"`WhereNumDecoder` only support maximum {max_where_conds} where clause\")\n",
    "        \n",
    "        self.lstm_q = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        self.lstm_h = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.col_self_attn = SelfAttention(2*hidden_size, 1)\n",
    "        self.lstm_q_hidden_init_linear = nn.Linear(2*hidden_size, 2*hidden_size)\n",
    "        self.lstm_q_cell_init_linear = nn.Linear(2*hidden_size, 2*hidden_size)\n",
    "        \n",
    "        self.context_self_attn = SelfAttention(hidden_size, 1)\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, question_padded, header_padded, col_padded, question_lengths: List[int], col_lengths: List[int], rt_attn=False):\n",
    "        r\"\"\"\n",
    "        predict agg index\n",
    "        select_prob: selected argmax indices of select_output score\n",
    "        \"\"\"\n",
    "        batch_size, n_col, _ = col_padded.size()\n",
    "        o_c, (h_c, c_c) = self.lstm_h(col_padded)  # o_c: (B, T_c, H)\n",
    "        o_h, (h_h, c_h) = self.lstm_h(header_padded)  # h_h: (n_direc*num_layers, B, H/2)\n",
    "        \n",
    "        header_summary = torch.cat([h for h in h_h[-2:]], dim=1).unsqueeze(1).repeat(1, n_col, 1)  # (B, T_c, H)\n",
    "        col_context = torch.cat([o_c, header_summary], dim=2)  # (B, T_c, 2H)\n",
    "\n",
    "        col_self_attn, col_attn = self.col_self_attn(col_context, col_lengths, rt_attn)  # (B, 2H), (B, T_c)\n",
    "\n",
    "        h_0 = self.lstm_q_hidden_init_linear(col_self_attn)  # (B, 2H)\n",
    "        h_0 = h_0.view(batch_size, 2*self.num_layers, -1).transpose(0, 1).contiguous()  # (B, 2*num_layers, H/2)\n",
    "        c_0 = self.lstm_q_cell_init_linear(col_self_attn)  # (B, 2H)\n",
    "        c_0 = c_0.view(batch_size, 2*self.num_layers, -1).transpose(0, 1).contiguous()  # (B, 2*num_layers, H/2)\n",
    "        \n",
    "        o_q, (h_q, c_q) = self.lstm_q(question_padded, (h_0, c_0))  # o_q: (B, T_q, H)\n",
    "        o_summary, o_attn = self.context_self_attn(o_q, question_lengths, rt_attn)  # (B, H), (B, T_q)\n",
    "        output = self.output_layer(o_summary)\n",
    "        \n",
    "        return output, (col_attn, o_attn)\n",
    "\n",
    "    \n",
    "class WhereColumnDecoder(nn.Module):\n",
    "    r\"\"\"WHERE Column Decoder\"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int=1, num_layers: int=2, dropout_ratio:float=0.3, max_where_conds: int=4) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "\n",
    "        self.lstm_q = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        self.lstm_h = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.col_context_linear = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.col2question_attn = C2QAttention(hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(2*hidden_size, 2*hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2*hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, question_padded, header_padded, col_padded, question_lengths: List[int], col_lengths: List[int], rt_attn=False):\n",
    "        r\"\"\"\n",
    "        predict column index\n",
    "        \"\"\"\n",
    "        batch_size, n_col, _ = col_padded.size()\n",
    "        o_q, (h_q, c_q) = self.lstm_q(question_padded)  # o_q: (B, T_q, H)\n",
    "        o_c, (h_c, c_c) = self.lstm_h(col_padded)  # o_c: (B, T_c, H)\n",
    "        o_h, (h_h, c_h) = self.lstm_h(header_padded)  # h_h: (n_direc*num_layers, B, H/2)\n",
    "        \n",
    "        header_summary = torch.cat([h for h in h_h[-2:]], dim=1).unsqueeze(1).repeat(1, n_col, 1)  # (B, T_c, H)\n",
    "        col_context = torch.cat([o_c, header_summary], dim=2)  # (B, T_c, 2H)\n",
    "        col_context = self.col_context_linear(col_context)  # (B, T_c, H)\n",
    "        col_q_context, attn = self.col2question_attn(col_context, o_q, question_lengths, col_lengths, rt_attn)  # (B, T_c, H), (B, T_c, T_q)\n",
    "        \n",
    "        vec = torch.cat([col_q_context, col_context], dim=2)  # (B, T_c, 2H)\n",
    "        output = self.output_layer(vec)\n",
    "        # TODO: add penalty for padded header(column) information\n",
    "        \n",
    "        return output.squeeze(-1), attn\n",
    "    \n",
    "    \n",
    "class WhereOpDecoder(nn.Module):\n",
    "    r\"\"\"WHERE Opperator Decoder\"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, num_layers: int=2, dropout_ratio: float=0.3, max_where_conds: int=4) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.max_where_conds = max_where_conds\n",
    "        \n",
    "        self.lstm_q = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        self.lstm_h = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.col_context_linear = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.col2question_attn = C2QAttention(hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(2*hidden_size, 2*hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2*hidden_size, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, question_padded, col_padded, question_lengths: List[int], where_nums: List[int], where_col_idxes: List[List[int]], rt_attn=False):\n",
    "        r\"\"\"\n",
    "        predict agg index\n",
    "        select_prob: selected argmax indices of select_output score\n",
    "        max_where_col_nums is settled at WhereColumnDecoder, but it can be lower than or equal to `max_where_conds`\n",
    "        \"\"\"\n",
    "        batch_size, n_col, _ = col_padded.size()\n",
    "        o_q, (h_q, c_q) = self.lstm_q(question_padded)  # o_q: (B, T_q, H)\n",
    "        o_c, (h_c, c_c) = self.lstm_h(col_padded)  # o_c: (B, T_c, H)\n",
    "        o_h, (h_h, c_h) = self.lstm_h(header_padded)  # h_h: (n_direc*num_layers, B, H/2)\n",
    "        \n",
    "        header_summary = torch.cat([h for h in h_h[-2:]], dim=1).unsqueeze(1).repeat(1, n_col, 1)  # (B, T_c, H)\n",
    "        col_context = torch.cat([o_c, header_summary], dim=2)  # (B, T_c, 2H)\n",
    "        col_context = self.col_context_linear(col_context)  # (B, T_c, H)\n",
    "        col_context_padded = self.get_context_padded(col_context, where_nums, where_col_idxes)  # (B, max_where_col_nums, H)\n",
    "        \n",
    "        col_q_context, attn = self.col2question_attn(col_context_padded, o_q, question_lengths, where_nums, rt_attn)  # (B, max_where_col_nums, H), (B, max_where_col_nums, T_q)\n",
    "        \n",
    "        vec = torch.cat([col_q_context, col_context_padded], dim=2)  # (B, max_where_col_nums, 2H)\n",
    "        output = self.output_layer(vec)  # (B, max_where_col_nums, n_cond_ops)\n",
    "        # TODO: add penalty for padded header(column) information\n",
    "        return output\n",
    "        \n",
    "    def get_context_padded(self, col_context, where_nums, where_col_idxes):\n",
    "        r\"\"\"\n",
    "        Select the where column index and pad if some batch doesn't match the max length of tensor\n",
    "        In case for have different where column lengths\n",
    "        \"\"\"\n",
    "        batch_size, n_col, hidden_size = col_context.size()\n",
    "        max_where_col_nums = max(where_nums)\n",
    "        batches = [col_context[i, batch_col] for i, batch_col in enumerate(where_col_idxes)]  # [(where_col_nums, hidden_size), ...]  len = B\n",
    "        batches_padded = []\n",
    "        for b in batches:\n",
    "            where_col_nums = b.size(0)\n",
    "            if where_col_nums < max_where_col_nums:\n",
    "                b_padded = torch.cat([b, torch.zeros((max_where_col_nums-where_col_nums), hidden_size, device=col_context.device)], dim=0)\n",
    "            else:\n",
    "                b_padded = b\n",
    "            batches_padded.append(b_padded)  # (max_where_col_nums, hidden_size)\n",
    "            \n",
    "        return torch.stack(batches_padded) # (B, max_where_col_nums, hidden_size)\n",
    "    \n",
    "    \n",
    "class WhereValueDecoder(nn.Module):\n",
    "    r\"\"\"WHERE Value Decoder\"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, num_layers: int=2, dropout_ratio: float=0.3, max_where_conds: int=4, n_cond_ops: int=4,\n",
    "                 start_tkn_id=8002, end_tkn_id=8003, embedding_layer=None) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.max_where_conds = max_where_conds\n",
    "        self.n_cond_ops = n_cond_ops\n",
    "        \n",
    "        self.start_tkn_id = start_tkn_id\n",
    "        self.end_tkn_id = end_tkn_id\n",
    "        if embedding_layer is None:\n",
    "            raise KeyError(\"Must initialize the embedding_layer to BertModel's word embedding layer\")\n",
    "        else:\n",
    "            self.embedding_layer = embedding_layer\n",
    "        self.lstm_q = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        self.lstm_h = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.col_context_linear = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.col2question_attn = C2QAttention(hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(2*hidden_size, 2*hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2*hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, question_padded, col_padded, question_lengths: List[int], where_nums: List[int], where_col_idxes: List[List[int]], where_op_idxes: List[List[int]], rt_attn=False):\n",
    "        r\"\"\"\n",
    "        predict agg index\n",
    "        select_prob: selected argmax indices of select_output score\n",
    "        max_where_col_nums is setted at WhereColumnDecoder\n",
    "        \"\"\"\n",
    "        batch_size, n_col, _ = col_padded.size()\n",
    "        o_q, (h_q, c_q) = self.lstm_q(question_padded)  # o_q: (B, T_q, H)\n",
    "        o_c, (h_c, c_c) = self.lstm_h(col_padded)  # o_c: (B, T_c, H)\n",
    "        o_h, (h_h, c_h) = self.lstm_h(header_padded)  # h_h: (n_direc*num_layers, B, H/2)\n",
    "        \n",
    "        header_summary = torch.cat([h for h in h_h[-2:]], dim=1).unsqueeze(1).repeat(1, n_col, 1)  # (B, T_c, H)\n",
    "        col_context = torch.cat([o_c, header_summary], dim=2)  # (B, T_c, 2H)\n",
    "        col_context = self.col_context_linear(col_context)  # (B, T_c, H)\n",
    "        col_context_padded = self.get_context_padded(col_context, where_nums, where_col_idxes)  # (B, max_where_col_nums, H)\n",
    "        \n",
    "        col_q_context, attn = self.col2question_attn(col_context_padded, o_q, question_lengths, where_nums, rt_attn)  # (B, max_where_col_nums, H), (B, max_where_col_nums, T_q)\n",
    "        \n",
    "        \n",
    "    def get_context_padded(self, col_context, where_nums, where_col_idxes):\n",
    "        r\"\"\"\n",
    "        Select the where column index and pad if some batch doesn't match the max length of tensor\n",
    "        In case for have different where column lengths\n",
    "        \"\"\"\n",
    "        batch_size, n_col, hidden_size = col_context.size()\n",
    "        max_where_col_nums = max(where_nums)\n",
    "        batches = [col_context[i, batch_col] for i, batch_col in enumerate(where_col_idxes)]  # [(where_col_nums, hidden_size), ...]  len = B\n",
    "        batches_padded = []\n",
    "        for b in batches:\n",
    "            where_col_nums = b.size(0)\n",
    "            if where_col_nums < max_where_col_nums:\n",
    "                b_padded = torch.cat([b, torch.zeros((max_where_col_nums-where_col_nums), hidden_size, device=col_context.device)], dim=0)\n",
    "            else:\n",
    "                b_padded = b\n",
    "            batches_padded.append(b_padded)  # (max_where_col_nums, hidden_size)\n",
    "            \n",
    "        return torch.stack(batches_padded) # (B, max_where_col_nums, hidden_size)\n",
    "    \n",
    "        \n",
    "    def start_token(self):\n",
    "        pass\n",
    "    \n",
    "    def decode(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d43125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = model_bert.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c0a57eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8003"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_tkn_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82b499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "853d1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = config_bert.hidden_size\n",
    "hidden_size = 100\n",
    "num_layers = 2\n",
    "dropout_ratio = 0.3\n",
    "max_where_num = 4\n",
    "n_agg_ops = len(dbengine.agg_ops)\n",
    "n_cond_ops = len(dbengine.cond_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68f015cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_decoder = SelectDecoder(\n",
    "    input_size, hidden_size, output_size=1, num_layers=num_layers, dropout_ratio=dropout_ratio\n",
    ")\n",
    "agg_decoder = AggDecoder(\n",
    "    input_size, hidden_size, output_size=n_agg_ops, num_layers=num_layers, dropout_ratio=dropout_ratio\n",
    ")\n",
    "where_num_decoder = WhereNumDecoder(\n",
    "    input_size, hidden_size, output_size=(max_where_num+1), num_layers=num_layers, dropout_ratio=dropout_ratio\n",
    ")\n",
    "where_col_decoder = WhereColumnDecoder(\n",
    "    input_size, hidden_size, output_size=1, num_layers=num_layers, dropout_ratio=dropout_ratio\n",
    ")\n",
    "where_op_decoder = WhereOpDecoder(\n",
    "    input_size, hidden_size, output_size=n_cond_ops, num_layers=num_layers, dropout_ratio=dropout_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "415376c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([16, 16],\n",
       " [0, 0],\n",
       " [2, 2],\n",
       " [[10, 3], [10, 3]],\n",
       " [[0, 0], [0, 0]],\n",
       " [['법인세차감전 순이익', 2018], ['유동자산', 2019]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_sc, g_sa, g_wn, g_wc, g_wo, g_wv = get_g(batch_sqls)\n",
    "g_sc, g_sa, g_wn, g_wc, g_wo, g_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c17baace",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sc, g_sa, g_wn, g_wc, g_wo, g_wv = [13, 2], [0, 1], [3, 1], [[1, 2, 3], [1]], [[0, 0, 1], [0]], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d428180",
   "metadata": {},
   "source": [
    "## Training: Decoding with max probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4aaace45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_decoder(typ, **kwargs):\n",
    "    r\"\"\"\n",
    "    if not using teacher force model will use this function to predict answer\n",
    "    \"\"\"\n",
    "    if typ == \"sc\":  # SELECT column\n",
    "        select_outputs = kwargs[\"select_outputs\"]\n",
    "        return select_outputs.argmax(1).tolist()\n",
    "    elif typ == \"sa\":  # SELECT aggregation operator\n",
    "        # not need actually\n",
    "        agg_outputs = kwargs[\"agg_outputs\"]\n",
    "        return agg_outputs.argmax(1)\n",
    "    elif typ == \"wn\":  # WHERE number\n",
    "        where_num_outputs = kwargs[\"where_num_outputs\"]\n",
    "        return where_num_outputs.argmax(1).tolist()\n",
    "    elif typ == \"wc\":  # WHERE clause column\n",
    "        where_col_argsort = kwargs[\"where_col_argsort\"]\n",
    "        where_nums = kwargs[\"where_nums\"]\n",
    "        where_col_idxes = [where_col_argsort[b_idx, :w_num].tolist() for b_idx, w_num in enumerate(where_nums)]\n",
    "        return where_col_idxes\n",
    "    elif typ == \"wo\":  # WHERE clause operator\n",
    "        where_op_outputs = kwargs[\"where_op_outputs\"]\n",
    "        where_nums = kwargs[\"where_nums\"]\n",
    "        where_op_idxes = [where_op_outputs.argmax(2)[b_idx, :w_num].tolist() for b_idx, w_num in enumerate(where_nums)]\n",
    "        return where_op_idxes\n",
    "    elif typ == \"wv\":  # WHERE clause value\n",
    "        pass\n",
    "    else:\n",
    "        raise KeyError(\"`typ` must be in ['sc', 'sa', 'wn', 'wc', 'wo', 'wv']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a876bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = {}\n",
    "\n",
    "select_outputs, _ = select_decoder(question_padded, header_padded, col_padded, question_lengths, col_lengths)\n",
    "select_idxes = g_sc if g_sc else predict_decoder(\"sc\", select_outputs=select_outputs)\n",
    "\n",
    "agg_outputs, _ = agg_decoder(question_padded, col_padded, question_lengths, col_lengths, select_idxes)\n",
    "\n",
    "where_num_outputs, _  = where_num_decoder(question_padded, header_padded, col_padded, question_lengths, col_lengths)\n",
    "where_nums = g_wn if g_wn else predict_decoder(\"wn\", where_num_outputs=where_num_outputs)\n",
    "\n",
    "where_col_outputs, _ = where_col_decoder(question_padded, header_padded, col_padded, question_lengths, col_lengths)\n",
    "where_col_argsort = torch.sigmoid(where_col_outputs).argsort(1)\n",
    "where_col_idxes = g_wc if g_wc else predict_decoder(\"wc\", where_col_argsort=where_col_argsort, where_nums=where_nums)\n",
    "\n",
    "where_op_outputs = where_op_decoder(question_padded, col_padded, question_lengths, where_nums, where_col_idxes)\n",
    "where_op_idxes = g_wo if g_wo else predict_decoder(\"wo\", where_op_outputs=where_op_outputs, where_nums=where_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "180ae58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1], [0]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "89eda0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [1]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_col_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23241da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0], [0]]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_decoder(\"wo\", where_op_outputs=where_op_outputs, where_nums=where_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c005c27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0], [0]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[where_op_outputs.argmax(2)[b_idx, :w_num].tolist() for b_idx, w_num in enumerate(where_nums)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d653b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39210ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 4, 1, 3], [7, 6, 5, 0]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_col_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "19e76eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_outputs, _ = agg_decoder(question_padded, col_padded, question_lengths, col_lengths, select_idxes)\n",
    "select_outputs, _ = select_decoder(question_padded, header_padded, col_padded, question_lengths, col_lengths)\n",
    "where_num_outputs, _  = where_num_decoder(question_padded, header_padded, col_padded, question_lengths, col_lengths)\n",
    "where_col_outputs, _ = where_col_decoder(question_padded, header_padded, col_padded, question_lengths, col_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "3dfa3d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_outputs.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6fdab96",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "topk(): argument 'k' (position 1) must be int, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-8e853159f2fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhere_col_prob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhere_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: topk(): argument 'k' (position 1) must be int, not Tensor"
     ]
    }
   ],
   "source": [
    "values, indices = [where_col_prob.topk(where_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8aab18a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5125, 0.5125, 0.5125, 0.5125, 0.5125, 0.5125],\n",
       "        [0.5120, 0.5120, 0.5120, 0.5120, 0.5120, 0.5120]],\n",
       "       grad_fn=<TopkBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87514411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  3, 19,  7,  1,  8],\n",
       "        [ 0,  7,  4,  6,  8,  3]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7347e1b6",
   "metadata": {},
   "source": [
    "## Testing: Execution-guided beam decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1bf2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6d964f",
   "metadata": {},
   "source": [
    "select "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b836ddaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_output, _ = select_decoder(question_padded, header_padded, col_padded, question_lengths)\n",
    "select_output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0dc2d",
   "metadata": {},
   "source": [
    "construct all possible select + (agg) score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "545035ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "batch_size, n_col = select_output.size()\n",
    "\n",
    "select_prob = torch.softmax(select_output, 1)  # prob_sc\n",
    "if n_col < beam_size:\n",
    "    beam_size_max_col = n_col\n",
    "else:\n",
    "    beam_size_max_col = beam_size\n",
    "\n",
    "prob_sc_sa = torch.zeros([batch_size, beam_size_max_col, n_agg_ops])\n",
    "prob_sca = torch.zeros_like(prob_sc_sa)\n",
    "print(prob_sca.size())  # (B, beam-size, n_agg_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a40f72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc top k: [[19, 18, 0, 14], [3, 4, 6, 5]]\n"
     ]
    }
   ],
   "source": [
    "# beamseacrh\n",
    "_, pr_sc_beam = select_output.topk(k=beam_size_max_col)\n",
    "print(f\"sc top k: {pr_sc_beam.tolist()}\")\n",
    "\n",
    "for i_beam in range(beam_size_max_col):\n",
    "    select_idx = pr_sc_beam[:, i_beam].tolist() # pr_sc\n",
    "    agg_output, _ = agg_decoder(question_padded, col_padded, question_lengths, select_idx)\n",
    "    agg_prob = torch.softmax(agg_output, dim=-1)  # prob_sa: (B, n_agg_ops)\n",
    "    prob_sc_sa[:, i_beam, :] = agg_prob\n",
    "    \n",
    "    prob_sc_selected = select_prob[range(batch_size), select_idx]  # (B,)\n",
    "    prob_sca[:, i_beam, :] = (agg_prob.t() * prob_sc_selected).t()  # (n_agg_ops, B) \\odot (1, B) (broadcast) -> (B, max_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9846ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1765, 0.1692, 0.1639, 0.1756, 0.1588, 0.1561],\n",
      "         [0.1777, 0.1687, 0.1647, 0.1742, 0.1588, 0.1558],\n",
      "         [0.1764, 0.1690, 0.1643, 0.1751, 0.1593, 0.1558],\n",
      "         [0.1779, 0.1693, 0.1647, 0.1732, 0.1581, 0.1568]],\n",
      "\n",
      "        [[0.1778, 0.1697, 0.1638, 0.1724, 0.1561, 0.1601],\n",
      "         [0.1778, 0.1712, 0.1638, 0.1742, 0.1554, 0.1577],\n",
      "         [0.1789, 0.1702, 0.1634, 0.1741, 0.1557, 0.1578],\n",
      "         [0.1774, 0.1712, 0.1640, 0.1729, 0.1564, 0.1581]]])\n"
     ]
    }
   ],
   "source": [
    "print(prob_sc_sa.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95fe0af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 6])\n",
      "tensor([[[0.0088, 0.0085, 0.0082, 0.0088, 0.0079, 0.0078],\n",
      "         [0.0089, 0.0084, 0.0082, 0.0087, 0.0079, 0.0078],\n",
      "         [0.0088, 0.0084, 0.0082, 0.0088, 0.0080, 0.0078],\n",
      "         [0.0089, 0.0085, 0.0082, 0.0087, 0.0079, 0.0078]],\n",
      "\n",
      "        [[0.0089, 0.0085, 0.0082, 0.0086, 0.0078, 0.0080],\n",
      "         [0.0089, 0.0086, 0.0082, 0.0087, 0.0078, 0.0079],\n",
      "         [0.0089, 0.0085, 0.0082, 0.0087, 0.0078, 0.0079],\n",
      "         [0.0089, 0.0086, 0.0082, 0.0086, 0.0078, 0.0079]]])\n"
     ]
    }
   ],
   "source": [
    "print(prob_sca.size())  # (B, beam_size, prob_sc(beam size selected) * prob_agg)\n",
    "print(prob_sca.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2ba5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_multi_dim(tensor, n_topk):\n",
    "    batch_size = tensor.size(0)\n",
    "    values_1d, idxes_1d = tensor.view(batch_size, -1).topk(n_topk)\n",
    "    idxes = np.stack(np.unravel_index(idxes_1d, tensor.size()[1:])).transpose(1, 2, 0)\n",
    "    values = tensor.view(batch_size, -1).gather(1, idxes_1d).numpy()\n",
    "    return idxes, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d77e68e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First flatten to 1-d\n",
    "if np.prod(prob_sca.shape[1:]) < beam_size:\n",
    "    beam_size_sca = np.prod(prob_sca.shape[1:])\n",
    "else:\n",
    "    beam_size_sca = beam_size\n",
    "# Now as sc_idx is already sorted, re-map them properly.\n",
    "# idxes: [sc_beam_idx, sa_idx] -> sca_idxes: [sc_idx, sa_idx]\n",
    "idxes, values = topk_multi_dim(prob_sca.detach().cpu(), n_topk=beam_size_sca)\n",
    "sc_beam_idxes = idxes[:, :, 0]\n",
    "sc_idxes = np.stack([pr_sc_beam.numpy()[i, sc_beam_idx] for i, sc_beam_idx in enumerate(sc_beam_idxes)])\n",
    "sca_idxes = np.stack([sc_idxes, idxes[:, :, 1]]).transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c8cf77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[14,  0],\n",
       "        [18,  0],\n",
       "        [19,  0],\n",
       "        [ 0,  0]],\n",
       "\n",
       "       [[ 6,  0],\n",
       "        [ 3,  0],\n",
       "        [ 4,  0],\n",
       "        [ 5,  0]]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sca_idxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f12bd",
   "metadata": {},
   "source": [
    "select agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2dfec904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 3]\n",
      "[7, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# argmax\n",
    "idxes = select_output.argmax(dim=1)\n",
    "print(idxes.tolist())\n",
    "\n",
    "# beamseacrh\n",
    "ith_beam = 0\n",
    "v, idxes = select_output.topk(k=4)\n",
    "print(idxes[:, ith_beam].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "63960e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_idx = idxes[:, ith_beam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "a0762034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_output, _  = agg_decoder(question_padded, col_padded, question_lengths, select_idx)\n",
    "agg_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9bdff2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_num_output, _  = where_num_decoder(question_padded, header_padded, col_padded, question_lengths, col_lengths)\n",
    "where_num_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "30b7ff14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_col_output, _ = where_col_decoder(question_padded, header_padded, col_padded, question_lengths)\n",
    "where_col_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f687e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_col_prob = torch.sigmoid(where_col_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b75710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ace7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_q = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "lstm_h = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "\n",
    "col2question_attn = C2QAttention(hidden_size, hidden_size)\n",
    "col_context_linear = nn.Linear(2*hidden_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b9ce85ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, n_col, _ = col_padded.size()\n",
    "o_q, (h_q, c_q) = lstm_q(question_padded)  # o_q: (B, T_q, H)\n",
    "o_c, (h_c, c_c) = lstm_h(col_padded)  # o_c: (B, T_c, H)\n",
    "o_h, (h_h, c_h) = lstm_h(header_padded)  # h_h: (n_direc*num_layers, B, H/2)\n",
    "\n",
    "header_summary = torch.cat([h for h in h_h[-2:]], dim=1).unsqueeze(1).repeat(1, n_col, 1) # (B, T_c, H)\n",
    "col_context = torch.cat([o_c, header_summary], dim=2)  # (B, T_c, 2H)\n",
    "col_context = col_context_linear(col_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44b98a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20, 100])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_context.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d24539ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 1], [[1, 2, 3], [1]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_nums, where_col_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aad7bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_padded(col_context, where_nums, where_col_idxes):\n",
    "    r\"\"\"\n",
    "    Select the where col index and pad it\n",
    "    In case for have different where column lengths\n",
    "    \"\"\"\n",
    "    batch_size, n_col, hidden_size = col_context.size()\n",
    "    max_where_col_nums = max(where_nums)\n",
    "    batches = [col_context[i, batch_col] for i, batch_col in enumerate(where_col_idxes)]  # [(where_col_nums, hidden_size), ...]  len = B\n",
    "    batches_padded = []\n",
    "    for b in batches:\n",
    "        where_col_nums = b.size(0)\n",
    "        if where_col_nums < max_where_col_nums:\n",
    "            b_padded = torch.cat([b, torch.zeros((max_where_col_nums-where_col_nums), hidden_size, device=col_context.device)], dim=0)\n",
    "        else:\n",
    "            b_padded = b\n",
    "        batches_padded.append(b_padded)  # (max_where_col_nums, hidden_size)\n",
    "    return torch.stack(batches_padded) # (B, max_where_col_nums, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "73347c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 100])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_context_padded = get_context_padded(col_context, where_nums, where_col_idxes)\n",
    "col_context_padded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "29291d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, a = col2question_attn(col_context_padded, o_q, question_lengths, where_nums, rt_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d33fcec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_where_col_nums = max(where_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d3cb21f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1133496a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1], [0]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_op_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "385e3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_op_one_hot = torch.zeros(batch_size, max_where_col_nums, n_cond_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d626a5ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter() received an invalid combination of arguments - got (Tensor, int, list, int), but expected one of:\n * (Tensor input, name dim, Tensor index, Tensor src)\n      didn't match because some of the arguments have invalid types: (Tensor, !int!, !list!, !int!)\n * (Tensor input, int dim, Tensor index, Tensor src)\n      didn't match because some of the arguments have invalid types: (Tensor, int, !list!, !int!)\n * (Tensor input, name dim, Tensor index, Number value)\n      didn't match because some of the arguments have invalid types: (Tensor, !int!, !list!, !int!)\n * (Tensor input, int dim, Tensor index, Number value)\n      didn't match because some of the arguments have invalid types: (Tensor, int, !list!, !int!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-16340dff3127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhere_op_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere_op_idxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: scatter() received an invalid combination of arguments - got (Tensor, int, list, int), but expected one of:\n * (Tensor input, name dim, Tensor index, Tensor src)\n      didn't match because some of the arguments have invalid types: (Tensor, !int!, !list!, !int!)\n * (Tensor input, int dim, Tensor index, Tensor src)\n      didn't match because some of the arguments have invalid types: (Tensor, int, !list!, !int!)\n * (Tensor input, name dim, Tensor index, Number value)\n      didn't match because some of the arguments have invalid types: (Tensor, !int!, !list!, !int!)\n * (Tensor input, int dim, Tensor index, Number value)\n      didn't match because some of the arguments have invalid types: (Tensor, int, !list!, !int!)\n"
     ]
    }
   ],
   "source": [
    "torch.scatter(where_op_one_hot, 2, where_op_idxes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "873e3e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch_col in enumerate(where_op_idxes):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4644ca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cond_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3aaf1164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [1]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_where_op_one_hot_padded(where_op_idxes, where_nums, where_col_idxes):\n",
    "    r\"\"\"\n",
    "    Select the where col index and pad it\n",
    "    In case for have different where column lengths\n",
    "    \"\"\"\n",
    "    batch_size, n_col, hidden_size = col_context.size()\n",
    "    max_where_col_nums = max(where_nums)\n",
    "    batches = [torch.zeros(where_num, n_cond_ops).scatter(1, torch.LongTensor(batch_col).unsqueeze(1), 1) for where_num, batch_col in zip(where_nums, where_op_idxes)]  \n",
    "    # [(where_col_nums, n_cond_ops), ...]  len = B\n",
    "    batches_padded = []\n",
    "    for b in batches:\n",
    "        where_col_nums = b.size(0)\n",
    "        if where_col_nums < max_where_col_nums:\n",
    "            b_padded = torch.cat([b, torch.zeros((max_where_col_nums-where_col_nums), hidden_size, device=col_context.device)], dim=0)\n",
    "        else:\n",
    "            b_padded = b\n",
    "        batches_padded.append(b_padded)  # (max_where_col_nums, hidden_size)\n",
    "    return torch.stack(batches_padded) # (B, max_where_col_nums, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ad7560c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(len(batch_col), n_cond_ops).scatter(1, torch.LongTensor(batch_col).unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2fdd6dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.]]),\n",
       " tensor([[1., 0., 0., 0.]])]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.zeros(where_num, n_cond_ops).scatter(1, torch.LongTensor(batch_col).unsqueeze(1), 1) for where_num, batch_col in zip(where_nums, where_op_idxes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e46a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab8a5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "21e4c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "wenc_op = []\n",
    "for b in range(batch_size):\n",
    "    # [[...], [...]]\n",
    "    # Pad list to maximum number of selections\n",
    "    wenc_op1 = torch.zeros(max_where_col_nums, n_cond_ops)\n",
    "    wo1 = where_op_idxes[b]\n",
    "    idx_scatter = []\n",
    "    l_wo1 = len(wo1)\n",
    "    for i_wo11 in range(max_where_col_nums):\n",
    "        if i_wo11 < l_wo1:\n",
    "            wo11 = wo1[i_wo11]\n",
    "            idx_scatter.append([int(wo11)])\n",
    "        else:\n",
    "            idx_scatter.append([3]) # not used anyway\n",
    "\n",
    "    wenc_op1 = wenc_op1.scatter(1, torch.tensor(idx_scatter), 1)\n",
    "\n",
    "    wenc_op.append(wenc_op1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bd86f204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(wenc_op).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "74c74753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [3], [3]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c4c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
