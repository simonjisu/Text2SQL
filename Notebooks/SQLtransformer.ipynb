{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e54dd0",
   "metadata": {},
   "source": [
    "# TEXT2SQL with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e44f63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTroch Version: 1.8.1\n",
      "Transfomers Version: 4.6.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "print(f\"PyTroch Version: {torch.__version__}\")\n",
    "print(f\"Transfomers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f2f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, List, Union, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6bbc7",
   "metadata": {},
   "source": [
    "## Data to build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78913fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import records\n",
    "\n",
    "schema_re = re.compile(r'\\((.+)\\)')\n",
    "num_re = re.compile(r'[-+]?\\d*\\.\\d+|\\d+')\n",
    "\n",
    "db_path = Path(\"./private\")\n",
    "db = records.Database(f\"sqlite:///{db_path / 'samsung_new.db'}\")\n",
    "\n",
    "table_id = \"receipts\"\n",
    "table_info = db.query('SELECT sql from sqlite_master WHERE tbl_name = :name', name=table_id).all()[0].sql\n",
    "schema_str = schema_re.findall(table_info.replace(\"\\n\", \"\"))[0]\n",
    "schema = {}\n",
    "for tup in schema_str.split(', '):\n",
    "    c, t = tup.split()\n",
    "    schema[c.strip('\"')] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df325e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 'INTEGER',\n",
       " 'rcept_no': 'TEXT',\n",
       " 'reprt_code': 'TEXT',\n",
       " 'bsns_year': 'INTEGER',\n",
       " 'corp_code': 'TEXT',\n",
       " 'stock_code': 'TEXT',\n",
       " 'fs_div': 'TEXT',\n",
       " 'fs_nm': 'TEXT',\n",
       " 'sj_div': 'TEXT',\n",
       " 'sj_nm': 'TEXT',\n",
       " 'account_nm': 'TEXT',\n",
       " 'thstrm_nm': 'TEXT',\n",
       " 'thstrm_dt': 'TEXT',\n",
       " 'thstrm_amount': 'INTEGER',\n",
       " 'frmtrm_nm': 'TEXT',\n",
       " 'frmtrm_dt': 'TEXT',\n",
       " 'frmtrm_amount': 'INTEGER',\n",
       " 'bfefrmtrm_nm': 'TEXT',\n",
       " 'bfefrmtrm_dt': 'TEXT',\n",
       " 'bfefrmtrm_amount': 'INTEGER'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sqlite can have NULL, INTEGER, REAL, TEXT, BLOB data type\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0c13f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INTEGER', 'TEXT'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(schema.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11809ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 제 51 기에 삼성전자의 유동자산은 어떻게 돼? [T] receipts [C] index [INTEGER] [C] rcept_no [TEXT] [C] reprt_code [TEXT] [C] bsns_year [INTEGER] [C] corp_code [TEXT] [C] stock_code [TEXT] [C] fs_div [TEXT] [C] fs_nm [TEXT] [C] sj_div [TEXT] [C] sj_nm [TEXT] [C] account_nm [TEXT] [C] thstrm_nm [TEXT] [C] thstrm_dt [TEXT] [C] thstrm_amount [INTEGER] [C] frmtrm_nm [TEXT] [C] frmtrm_dt [TEXT] [C] frmtrm_amount [INTEGER] [C] bfefrmtrm_nm [TEXT] [C] bfefrmtrm_dt [TEXT] [C] bfefrmtrm_amount [INTEGER]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"제 51 기에 삼성전자의 유동자산은 어떻게 돼?\"\n",
    "cls_token = \"[CLS]\"\n",
    "table_token = \"[T]\"\n",
    "column_token = \"[C]\"\n",
    "\n",
    "f\"{cls_token} {question} [T] {table_id} \" + \" \".join([f\"{column_token} {col} [{typ}]\" for col, typ in schema.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f09690",
   "metadata": {},
   "source": [
    "## Build a cumstom Tokenizer\n",
    "\n",
    "https://huggingface.co/docs/tokenizers/python/latest/pipeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd7ee0e",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "- `normalizers`는 raw text를 더 깨끗하게 만드는 과정이다.\n",
    "- `NFD` 사용하게 되면 한글은 자음 모음으로 분리된다.\n",
    "    - NFD(Normalization Form Canonical Decomposition) = 조합형\n",
    "    - NFC(Normalizaiton Form Canonical Compostion) = 완성형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4528adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제 51 기에 삼성전자의 유동자산은 어떻게 돼?\n",
      "ᄌ/ᅦ/ /5/1/ /ᄀ/ᅵ/ᄋ/ᅦ/ /ᄉ/ᅡ/ᆷ/ᄉ/ᅥ/ᆼ/ᄌ/ᅥ/ᆫ/ᄌ/ᅡ/ᄋ/ᅴ/ /ᄋ/ᅲ/ᄃ/ᅩ/ᆼ/ᄌ/ᅡ/ᄉ/ᅡ/ᆫ/ᄋ/ᅳ/ᆫ/ /ᄋ/ᅥ/ᄄ/ᅥ/ᇂ/ᄀ/ᅦ/ /ᄃ/ᅫ/?\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import NFD, StripAccents\n",
    "\n",
    "normalizer = normalizers.Sequence([NFD(), StripAccents()])\n",
    "# 일반 출력시 합쳐져서 보이지만, for문을 사용하면 분리된다. \n",
    "print(normalizer.normalize_str(question))\n",
    "print(\"/\".join([x for x in normalizer.normalize_str(question)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24142f4",
   "metadata": {},
   "source": [
    "### Pre-Tokenization\n",
    "\n",
    "- `pre_tokenizers`는 텍스트를 더 작은 토큰으로 분리하는 과정이다.\n",
    "- `Whitespace`는 토큰을 공백을 기준으로 나누면 string의 위치를 같이 반환한다. (start + end) - 기준 regex: `\\w+|[^\\w\\s]+`\n",
    "- `Punctuation`은 문장 부호를 각각 분리한다. \n",
    "- `Digits`를 통해 숫자를 각각 분리할지 말지 결정할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2492e493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitespace: \n",
      "[('제', (0, 1)), ('51', (2, 4)), ('기에', (5, 7)), ('삼성전자의', (8, 13)), ('유동자산은', (14, 19)), ('어떻게', (20, 23)), ('돼', (24, 25)), ('?', (25, 26))]\n",
      "Digits individual: False\n",
      "[('제', (0, 1)), ('51', (2, 4)), ('기에', (5, 7)), ('삼성전자의', (8, 13)), ('유동자산은', (14, 19)), ('어떻게', (20, 23)), ('돼', (24, 25)), ('?????', (25, 30))]\n",
      "Punctuation + Individual Digits\n",
      "[('제', (0, 1)), ('5', (2, 3)), ('1', (3, 4)), ('기에', (5, 7)), ('삼성전자의', (8, 13)), ('유동자산은', (14, 19)), ('어떻게', (20, 23)), ('돼', (24, 25)), ('?', (25, 26)), ('?', (26, 27)), ('?', (27, 28)), ('?', (28, 29)), ('?', (29, 30))]\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import pre_tokenizers\n",
    "from tokenizers.pre_tokenizers import Whitespace, Punctuation, Digits\n",
    "\n",
    "print(\"Whitespace: \")\n",
    "print(Whitespace().pre_tokenize_str(question))\n",
    "\n",
    "print(\"Digits individual: False\")\n",
    "pre_tokenizer = pre_tokenizers.Sequence([Whitespace(), Digits(individual_digits=False)])\n",
    "print(pre_tokenizer.pre_tokenize_str(question + \"????\"))\n",
    "\n",
    "print(\"Punctuation + Individual Digits\")\n",
    "pre_tokenizer = pre_tokenizers.Sequence([Whitespace(), Punctuation(), Digits(individual_digits=True)])\n",
    "print(pre_tokenizer.pre_tokenize_str(question + \"????\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbeff6",
   "metadata": {},
   "source": [
    "### The Model\n",
    "\n",
    "- `BPE`: Byte-Pair Encoding 토큰화, 자주 등장하는 character를 합쳐서 표현하는 알고리즘\n",
    "- `Unigram`: 확률적으로 최적의 subword 토큰을 결정\n",
    "- `WordLevel`: 단어 단위의 토큰화\n",
    "- `WordPiece`: Google WordPiece 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e774115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.models import BPE, Unigram, WordLevel, WordPiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67fd70",
   "metadata": {},
   "source": [
    "### Post-Processing\n",
    "\n",
    "- `processors` 에서 후처리를 할 수 있다.\n",
    "- `TemplateProcessing`을 이용해 원하는 형태로 토큰을 분리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dad10a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.processors import PostProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "post_processor = TemplateProcessing(\n",
    "    single=\"[CLS] $A [T] $B [C] $B\",\n",
    "    pair=\"[CLS] $A [T] $B:1 [C] $B:1\",\n",
    "    special_tokens=[(\"[CLS]\", 1), (\"[SEP]\", 2)]#, (\"[T]\", 3), (\"[C]\", 4), (\"[INTEGER]\", 5), (\"[REAL]\", 6), (\"[TEXT]\", 7), (\"[BLOB]\", 8)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06448dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80fa71",
   "metadata": {},
   "source": [
    "- https://huggingface.co/docs/tokenizers/python/latest/index.html\n",
    "- https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=pretrainedtokenizer#transformers.PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6284c6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제 51 기에 삼성전자의 유동자산은 어떻게 돼? [T] receipts [SEP]index[SEP]rcept_no[SEP]reprt_code[SEP]bsns_year[SEP]corp_code[SEP]stock_code[SEP]fs_div[SEP]fs_nm[SEP]sj_div[SEP]sj_nm[SEP]account_nm[SEP]thstrm_nm[SEP]thstrm_dt[SEP]thstrm_amount[SEP]frmtrm_nm[SEP]frmtrm_dt[SEP]frmtrm_amount[SEP]bfefrmtrm_nm[SEP]bfefrmtrm_dt[SEP]bfefrmtrm_amount'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str = f\"{question} [T] {table_id} \" + \"\".join([f\"[SEP]{col}\" for col in schema]) \n",
    "# \" \".join([f\"{column_token} {col} [{typ}]\" for col, typ in schema.items()])\n",
    "input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e92449e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_qs = [\"제 51 기에 삼성전자의 유동자산은 어떻게 돼?\", \"2020년도 삼성전자의 유동자산은 얼마?\"]\n",
    "table_str = f\"[T]{table_id}\" + \"\".join([f\"[SEP]{col}\" for col in schema]) \n",
    "batch_ts = [table_str] * len(batch_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0870694c-179a-405c-807c-a672c904121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from KoBertTokenizer import KoBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6821b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_special_tokens = [\"[T]\", \"[C]\", \"[INTEGER]\", \"[REAL]\", \"[TEXT]\", \"[BLOB]\"]\n",
    "# new_special_tokens = list(map(lambda x: AddedToken(x, single_word=True, normalized=False), new_special_tokens))\n",
    "# tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert', add_special_tokens=True, additional_special_tokens=new_special_tokens)\n",
    "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "586388a6-ce7a-432b-801b-8b977306367c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[T]': 8002,\n",
       " '[C]': 8003,\n",
       " '[INTEGER]': 8004,\n",
       " '[REAL]': 8005,\n",
       " '[TEXT]': 8006,\n",
       " '[BLOB]': 8007}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokenes2idx = dict(zip(tokenizer.additional_special_tokens, tokenizer.additional_special_tokens_ids))\n",
    "special_tokenes2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9826cafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_input = tokenizer(\n",
    "    batch_qs, batch_ts, \n",
    "    max_length=512, padding=True, truncation=True, return_tensors=\"pt\", \n",
    "    return_attention_mask=True, \n",
    "    return_special_tokens_mask=False, \n",
    ")\n",
    "encode_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "419bfac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size, max_length = encode_input[\"input_ids\"].size()\n",
    "question_mask = torch.bitwise_and(encode_input[\"token_type_ids\"] == 0, encode_input[\"attention_mask\"].bool())\n",
    "question_mask[:, 0] = False  # [CLS] mask out\n",
    "question_mask[:, -1] = False  # [SEP] mask out\n",
    "\n",
    "# table_mask = torch.where(\n",
    "#     (encode_input[\"input_ids\"] == 8002), \n",
    "#     torch.ones_like(encode_input[\"input_ids\"], dtype=torch.bool), \n",
    "#     torch.zeros_like(encode_input[\"input_ids\"], dtype=torch.bool)\n",
    "# )\n",
    "# column_mask = torch.where(\n",
    "#     (encode_input[\"input_ids\"] == 8003),\n",
    "#     torch.ones_like(encode_input[\"input_ids\"], dtype=torch.bool), \n",
    "#     torch.zeros_like(encode_input[\"input_ids\"], dtype=torch.bool)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03b989bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 제 51 기에 삼성전자의 유동자산은 어떻게 돼?[SEP] [T] receipts [C] index [INTEGER] [C] rcept_no [TEXT] [C] reprt_code [TEXT] [C] bsns_year [INTEGER] [C] corp_code [TEXT] [C] stock_code [TEXT] [C] fs_div [TEXT] [C] fs_nm [TEXT] [C] sj_div [TEXT] [C] sj_nm [TEXT] [C] account_nm [TEXT] [C] thstrm_nm [TEXT] [C] thstrm_dt [TEXT] [C] thstrm_amount [INTEGER] [C] frmtrm_nm [TEXT] [C] frmtrm_dt [TEXT] [C] frmtrm_amount [INTEGER] [C] bfefrmtrm_nm [TEXT] [C] bfefrmtrm_dt [TEXT] [C] bfefrmtrm_amount [INTEGER] [SEP]\n",
      "\n",
      "[CLS] 2020년도 삼성전자의 유동자산은 얼마?[SEP] [T] receipts [C] index [INTEGER] [C] rcept_no [TEXT] [C] reprt_code [TEXT] [C] bsns_year [INTEGER] [C] corp_code [TEXT] [C] stock_code [TEXT] [C] fs_div [TEXT] [C] fs_nm [TEXT] [C] sj_div [TEXT] [C] sj_nm [TEXT] [C] account_nm [TEXT] [C] thstrm_nm [TEXT] [C] thstrm_dt [TEXT] [C] thstrm_amount [INTEGER] [C] frmtrm_nm [TEXT] [C] frmtrm_dt [TEXT] [C] frmtrm_amount [INTEGER] [C] bfefrmtrm_nm [TEXT] [C] bfefrmtrm_dt [TEXT] [C] bfefrmtrm_amount [INTEGER] [SEP][PAD][PAD]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in encode_input[\"input_ids\"]:\n",
    "    print(tokenizer.decode(x, skip_special_tokens=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9c45eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- type_ids = 0\n",
      "[CLS] 제 51 기에 삼성전자의 유동자산은 어떻게 돼?[SEP]\n",
      "--- type_ids = 1\n",
      "[T] receipts [C] index [INTEGER] [C] rcept_no [TEXT] [C] reprt_code [TEXT] [C] bsns_year [INTEGER] [C] corp_code [TEXT] [C] stock_code [TEXT] [C] fs_div [TEXT] [C] fs_nm [TEXT] [C] sj_div [TEXT] [C] sj_nm [TEXT] [C] account_nm [TEXT] [C] thstrm_nm [TEXT] [C] thstrm_dt [TEXT] [C] thstrm_amount [INTEGER] [C] frmtrm_nm [TEXT] [C] frmtrm_dt [TEXT] [C] frmtrm_amount [INTEGER] [C] bfefrmtrm_nm [TEXT] [C] bfefrmtrm_dt [TEXT] [C] bfefrmtrm_amount [INTEGER] [SEP]\n",
      "\n",
      "--- type_ids = 0\n",
      "[CLS] 2020년도 삼성전자의 유동자산은 얼마?[SEP]\n",
      "--- type_ids = 1\n",
      "[T] receipts [C] index [INTEGER] [C] rcept_no [TEXT] [C] reprt_code [TEXT] [C] bsns_year [INTEGER] [C] corp_code [TEXT] [C] stock_code [TEXT] [C] fs_div [TEXT] [C] fs_nm [TEXT] [C] sj_div [TEXT] [C] sj_nm [TEXT] [C] account_nm [TEXT] [C] thstrm_nm [TEXT] [C] thstrm_dt [TEXT] [C] thstrm_amount [INTEGER] [C] frmtrm_nm [TEXT] [C] frmtrm_dt [TEXT] [C] frmtrm_amount [INTEGER] [C] bfefrmtrm_nm [TEXT] [C] bfefrmtrm_dt [TEXT] [C] bfefrmtrm_amount [INTEGER] [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inputs, type_ids in zip(encode_input[\"input_ids\"], encode_input[\"token_type_ids\"]):\n",
    "    print(\"--- type_ids = 0\")\n",
    "    print(tokenizer.decode(inputs[type_ids == 0]).replace(\"[PAD]\", \"\"))\n",
    "    print(\"--- type_ids = 1\")\n",
    "    print(tokenizer.decode(inputs[type_ids == 1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3f9c0-0c9c-45b3-8eff-b902bb65ca6e",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4da48d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(8008, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "model = BertModel.from_pretrained(\"monologg/kobert\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80fc48fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_output = model(**encode_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "309bc33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_questions(batches: Tuple[torch.Tensor], question_lengths: List[int], model: BertModel, pad_idx: int=1) -> torch.Tensor:\n",
    "    padded = []\n",
    "    max_length = max(question_lengths)\n",
    "    for x in batches:\n",
    "        if len(x) < max_length:\n",
    "            pad_tensor = model.embeddings.word_embeddings(torch.LongTensor([pad_idx]*(max_length - len(x))))\n",
    "            padded.append(torch.cat([x, pad_tensor]))\n",
    "        else:\n",
    "            padded.append(x)\n",
    "    return torch.stack(padded)\n",
    "\n",
    "def get_batches_to_decoder(encode_output, mask, model, pad_idx):\n",
    "    lengths = mask.sum(1).tolist()\n",
    "    tensors = encode_output.last_hidden_state[mask, :]\n",
    "    batches = torch.split(tensors, lengths)\n",
    "    tensors_padded = pad_questions(batches, lengths, model, pad_idx=pad_idx)\n",
    "    return tensors_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d56a1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to question tokens and column tokens\n",
    "question_padded = get_batches_to_decoder(encode_output, question_mask, model, pad_idx=tokenizer.pad_token_id)\n",
    "table_padded = get_batches_to_decoder(encode_output, table_mask, model, pad_idx=tokenizer.pad_token_id)\n",
    "column_padded = get_batches_to_decoder(encode_output, column_mask, model, pad_idx=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6441cbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 16, 768]), torch.Size([2, 1, 768]), torch.Size([2, 20, 768]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_padded.size(), table_padded.size(), column_padded.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f8e440-8366-4997-b607-1d0028a313d0",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1PW9oAXfW-ZI-jxGn5q9O_gzUIZnNYaet\" alt=\"Sqlova Decoder Architecture \" width=\"100%\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a9be35-0d9e-4eaf-b956-87b7cd2ef99c",
   "metadata": {},
   "source": [
    "### Select Column\n",
    "\n",
    "$$\\begin{aligned} \n",
    "s(n\\vert c) &= D_c^T W E_n \\\\\n",
    "p(n\\vert c) &= \\text{softmax}(s(n\\vert c))\\\\\n",
    "C_c &= \\sum_n p(n \\vert c) E_n \\\\\n",
    "s_{sc}(c) &= W  \\tanh ([WD_c; WC_c]) \\\\\n",
    "p_{sc}(c) &= \\text{softmax}(s_{sc}(c))\n",
    "\\tanh\n",
    "\\end{aligned}$$\n",
    "\n",
    "$E_n$ is LSTM output of $n$-th token of question, $D_c$ is the encoding of header $c$, $C_n$ is context vector of question for given column, $[\\cdot ; \\cdot]$ is concatenation of two vectors, $p_{sc}(c)$ is probability of generating column c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c013d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderAttention(nn.Module):\n",
    "    r\"\"\"Decoder Attention Module\"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        r\"\"\"\n",
    "        Attention Module\n",
    "        $$ f(X) = W_1 \\tanh ( W_2 X ) $$\n",
    "        \"\"\"\n",
    "        self.W1 = nn.Linear(in_features, out_features)\n",
    "        self.W2 = nn.Linear(2*in_features, out_features)\n",
    "\n",
    "class SelectDecoder(nn.Module):\n",
    "    r\"\"\"SELECT Decoder\"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int, dropout_ratio:float) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        \n",
    "        self.lstm_q = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        self.lstm_h = nn.LSTM(input_size, int(hidden_size / 2), num_layers, dropout=dropout_ratio, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba472e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937b83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70294fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f555bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4947934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "5cd12706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 247, 768])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_output.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "484a3443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_output.pooler_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3511a4d0-a18e-497f-9611-23f8e713153a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55e67524",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55059e-d6c9-408f-814c-b033cab9390b",
   "metadata": {},
   "source": [
    "# Using Existing SQLova Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48a33621-b5c9-4d76-a2aa-d78677e31b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlova.model.nl2sql.wikisql_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085a56d-85a1-41cb-abb2-f394913f1c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
